[
  {
    "objectID": "assignment/index.html",
    "href": "assignment/index.html",
    "title": "Assignments",
    "section": "",
    "text": "The main goals of this class are to help you design, critique, code, and run rigorous, valid, and feasible evaluations of public sector programs. Each type of assignment in this class is designed to help you achieve one or more of these goals."
  },
  {
    "objectID": "assignment/index.html#weekly-check-in",
    "href": "assignment/index.html#weekly-check-in",
    "title": "Assignments",
    "section": "Weekly check-in",
    "text": "Weekly check-in\nEvery week, after you finish working through the content, I want to hear about what you learned and what questions you still have. Because the content in thsi course is flipped, these questions are crucial for our weekly in-class discussions.\nTo encourage engagement with the course content—and to allow me to collect the class’s questions each week—you’ll need to fill out a short response on iCollege. This should be ≈150 words. That’s fairly short: there are ≈250 words on a typical double-spaced page in Microsoft Word (500 when single-spaced).\nThese check-ins are due by noon on the days we have class. This is so I can look through the responses and start structuring the discussion for the evening’s class.\nYou should answer these two questions each week:\n\nWhat were the three (3) most interesting or exciting things you learned from the session? Why?\nWhat were the three (3) muddiest or unclear things from the session this week? What are you still wondering about?\n\nYou can include more than three interesting or muddiest things, but you must include at least three. There should be six easily identifiable things in each check-in: three exciting things and three questions.\nI will grade these check-ins using a check system:\n\n✔+: (11.5 points (115%) in gradebook) Response shows phenomenal thought and engagement with the course content. I will not assign these often.\n✔: (10 points (100%) in gradebook) Response is thoughtful, well-written, and shows engagement with the course content. This is the expected level of performance.\n✔−: (5 points (50%) in gradebook) Response is hastily composed, too short, and/or only cursorily engages with the course content. This grade signals that you need to improve next time. I will hopefully not assign these often.\n\nNotice that is essentially a pass/fail or completion-based system. I’m not grading your writing ability, I’m not counting the exact number of words you’re writing, and I’m not looking for encyclopedic citations of every single reading to prove that you did indeed read everything. I’m looking for thoughtful engagement, three interesting things, and three questions. That’s all. Do good work and you’ll get a ✓.\nYou will submit these check-ins via iCollege."
  },
  {
    "objectID": "assignment/index.html#problem-sets",
    "href": "assignment/index.html#problem-sets",
    "title": "Assignments",
    "section": "Problem sets",
    "text": "Problem sets\nTo practice writing R code, running inferential models, and thinking about causation, you will complete a series of problem sets.\nYou need to show that you made a good faith effort to work each question. I will not grade these in detail. The problem sets will be graded using a check system:\n\n✔+: (33 points (110%) in gradebook) Assignment is 100% completed. Every question was attempted and answered, and most answers are correct. Document is clean and easy to follow. Work is exceptional. I will not assign these often.\n✔: (30 points (100%) in gradebook) Assignment is 70–99% complete and most answers are correct. This is the expected level of performance.\n✔−: (15 points (50%) in gradebook) Assignment is less than 70% complete and/or most answers are incorrect. This indicates that you need to improve next time. I will hopefully not asisgn these often.\n\nYou may (and should!) work together on the problem sets, but you must turn in your own answers. You cannot work in groups of more than four people, and you must note who participated in the group in your assignment."
  },
  {
    "objectID": "assignment/index.html#evaluation-assignments",
    "href": "assignment/index.html#evaluation-assignments",
    "title": "Assignments",
    "section": "Evaluation assignments",
    "text": "Evaluation assignments\nFor your final project, you will conduct a pre-registered evaluation of a social program using synthetic data. To (1) give you practice with the principles of program evaluation, research design, measurement, and causal diagrams, and (2) help you with the foundation of your final project, you will complete a set of four evaluation-related assignments.\nIdeally these will become major sections of your final project. However, there is no requirement that the programs you use in these assignments must be the same as the final project. If, through these assignments, you discover that your initially chosen program is too simple, too complex, too boring, etc., you can change at any time.\nThese assignments will be graded using a check system:\n\n✔+: (33 points (110%) in gradebook) Assignment is 100% completed. Every question was attempted and answered, and most answers are correct. Document is clean and easy to follow. Work is exceptional. I will not assign these often.\n✔: (30 points (100%) in gradebook) Assignment is 70–99% complete and most answers are correct. This is the expected level of performance.\n✔−: (15 points (50%) in gradebook) Assignment is less than 70% complete and/or most answers are incorrect. This indicates that you need to improve next time. I will hopefully not asisgn these often."
  },
  {
    "objectID": "assignment/index.html#exams",
    "href": "assignment/index.html#exams",
    "title": "Assignments",
    "section": "Exams",
    "text": "Exams\nThere will be two exams covering (1) program evaluation, design, and causation, and (2) the core statistical tools of program evaluation and causal inference.\nYou will take these exams online through iCollege. The exams will have a time limit, but you can use notes and readings and the Google. You must take the exams on your own though, and not talk to anyone about them."
  },
  {
    "objectID": "assignment/index.html#final-project",
    "href": "assignment/index.html#final-project",
    "title": "Assignments",
    "section": "Final project",
    "text": "Final project\nAt the end of the course, you will demonstrate your knowledge of program evaluation and causal inference by completing a final project.\nComplete details for the final project are here.\nThere is no final exam. This project is your final exam."
  },
  {
    "objectID": "class/01-class.html#lecturas",
    "href": "class/01-class.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas"
  },
  {
    "objectID": "class/02-class.html#lecturas",
    "href": "class/02-class.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas"
  },
  {
    "objectID": "class/03-class.html#lecturas",
    "href": "class/03-class.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas"
  },
  {
    "objectID": "class/04-class.html#lecturas",
    "href": "class/04-class.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas"
  },
  {
    "objectID": "class/05-class.html#lecturas",
    "href": "class/05-class.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas"
  },
  {
    "objectID": "class/06-class.html#lecturas",
    "href": "class/06-class.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas"
  },
  {
    "objectID": "class/07-class.html#lecturas",
    "href": "class/07-class.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas"
  },
  {
    "objectID": "class/08-class.html#lecturas",
    "href": "class/08-class.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas"
  },
  {
    "objectID": "class/09-class.html#lecturas",
    "href": "class/09-class.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas"
  },
  {
    "objectID": "class/index.html",
    "href": "class/index.html",
    "title": "Presentaciones y lecturas",
    "section": "",
    "text": "En esta sección se encuentran las presentaciones de las clases lectivas de la cátedra de Estadística Descriptiva.\nTodo el material es accesible desde el menú de la izquierda <–"
  },
  {
    "objectID": "content/01-content.html",
    "href": "content/01-content.html",
    "title": "Práctica 1. Introducción al lenguaje R",
    "section": "",
    "text": "El objetivo de esta guía práctica es introducirnos a las herramientas que permiten establecer un flujo de trabajo en R.\nEn detalle, aprenderemos:\n\nCómo establecer un flujo de trabajo mediante scripts y Rprojects siguiendo el protocolo IPO\nCómo crear un proyecto de R (R.proyect)\nCómo crear un script (hoja) en R\n\n\n\n\nR es un lenguaje y ambiente de programación, dentro del cual se pueden implementar técnicas estadísticas y de ciencia de datos. Por su parte, RStudio es un IDE (integrated development enviroment) para R, o en pocas palabras, es una interfaz más amigable que nos permite interactuar con R.\n¿Y por qué aprender R? Existen muchas razones, pero algunas de las principales son:\n\nEmpleabilidad\nCrisis de reproducibilidad y Ciencia Abierta\nFacilita manipulación, almacenaje, cálculos y visualización de datos\nFacilita la colaboración y trabajo en equipo\nSimple, pero potente\nPuede integrarse con otros ambientes y herramientas\n\n\n\n\n\n\n\n\n\n\nAl momento de abrir RStudio por primera vez puede que nos asustemos, pues es un entorno nuevo lleno de posibilidades en donde todavía no conocemos mucho.\n\n\n\n\n\n\n\n\n\n¡Pero que no cunda el pánico! ya que estas posibilidades son nuevas oportunidades de aprendizaje en un software libre, gratuito y cada vez más utilizado en las ciencias sociales. ¿Nos vamos a equivocar? Claro que sí, y esperemos que así sea pues más aprenderemos.\n\n\n\n\n\n\n\n\n\nAl ver RStudio por primera vez se nos presentará una interfaz de al menos cuatro paneles.\n\n\n\n\n\n\n\n\n\n¡VEAMOS COMO COMENZAR A USAR R!\n\n\n\nTal vez una de las dificultades más comunes o cotidianas del uso de R es el orden de trabajo, en donde tenemos cientos de archivos, scripts, gráficos, bases de datos u otros repartidos desordenadamente en nuestro computador. También se da mucho el caso en que, cuando queremos trabajar con alguien, tenemos que cambiar las rutas de los archivos, por ejemplo en dónde están las bases de datos, ya que nuestros ordenadores y usuarios se llaman y son escencialmente distintos.\n¿Cómo podemos sortear eso? Siguiendo un flujo de trabajo reproducible, autocontenido y ordenado. En este curso trabajaremos R con un flujo de trabajo reproducible, basado en el sistema IPO. El protocolor IPO es una plantilla/protocolo de estructura digital de carpetas que tiene por objetivo el organizar, procesar y documentar los datos de un proyecto de investigación con miras a la apertura de los datos en un repositorio público y de acceso libre. En concreto, el sistema IPO se propone abordar brevemente todo lo referente a los Datos, Métodos y Resultados.\n\n\n\n\n\n\n\n\n\nLleva este nombre por el sistema de carpetas que se implementan: Input, Procesamiento y Output. En la carpeta Input guardaremos todos aquellso recursos iniciales que usaremos, como las bases de datos, el libro de códigos, entre otros. En la carpeta de Procesamiento, como dice el nombre, guardaremos todos los archivos que procesen y analicen datos. En la carpeta Output guardaremos todo aquello que hayamos producido en los archivos de procesamiento, como las bases de datos procesadas listas para compartir o publicas, los documentos de reporte, informes o analísis, gráficos o tablas.\n\n\n\n\n\n\n\n\n\nLa implementación de la reproducibilidad en este tipo de protocolos se basa en generar un conjunto de archivos auto-contenidos organizado en una estructura de proyecto que cualquier persona pueda compartir y ejecutar. En otras palabras, debe tener todo lo que necesita para ejecutar y volver a ejecutar el análisis. Para conocer más, visita el Laboratorio de Ciencia Abierta.\n\n\n\n\n\n\n\n\n\n\n\n\n¿Y cómo hacemos lo anterior? Mediante los Rproject. Los proyectos en R, o R Projects, serán el centro a partir del cual estaremos trabajando el resto de archivos incluidos en nuestro trabajo con los datos (Input, Procesamiento y Output). En pocas palabras, el Rproject será el elemento raíz de nuestro proyecto y que articula o abraza todos los demás componentes.\n\n\n\n\n\n\n\n\n\n¿Cómo lo hacemos? Es bastante sencillo. Nos dirigiremos a la sección superior derecha de RStudio, donde se encuentra una R dentro de un cubo:\n\n\n\n\n\n\n\n\n\nHacemos click en ella, y luego se nos desplegará una ventana con distintas opciones. Seleccionamos New Project.\n\n\n\n\n\n\n\n\n\nLuego, seleccionamos New Directory > New Project\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUna vez realizado lo anterior, nos pedirá asignar un Directory name, que es como se llamará nuestro proyecto. Se recomienda que tenga nombres sustantivos. En este ejemplo, le llamaremos tarea01.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLuego debemos indicarle dónde queremos que esté alojado en nuestro computador este proyecto. Para ello pinchamos en el Browse, y se nos desplegará nuestro sistema de carpetas de nuestro computador. Supongamos que queremos guardarlo en una carpeta que llamaremos Estadistica Descriptiva 2023.\n\n\n\n\n\n\n\n\n\nSeleccionamos la carpeta y le damos a Open o Abrir. Una vez realizado lo anterior, volveremos a RStudio y tendremos nuestro projecto abierto. Además, podemos ver que nuestro .Rproj se creó en la carpeta respectiva en la esquina inferior derecha de la pantalla.\n\n\n\n\n\n\n\n\n\nAhora, tenemos que darle el formato de flujo de trabajo reproducible. Para ello, crearemos las carpetas de Input, Procesamiento y Ouput en la misma carpeta Estadistica Descriptiva 2023 donde tenemos alojado el .Rproject.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n¿Y podemos ver esto mismo pero en RStudio? ¡Claro que sí!, cada carpeta que creemos se irá sumando al visualizador de Files, así como también si subimos archivos (como bases de datos) en las respectivas subcarpetas, irán apareciendo allí.\n\n\n\n\n\n\n\n\n\n¡HEMOS CREADO NUESTRO PROYECTO Y SISTEMA DE TRABAJO REPRODUCIBLE!\n\n\n\n\n\n\n\n\n\n\n\n\nPara comenzar a trabajar en R, lo primero es crear un Script. ¿Qué es un script? En términos simples, un script es la hoja en donde escribiremos y guardaremos nuestro código, y en donde a la vez podremos ir ordenando nuestros pasos e incluso ir comentándolos. Cuando hablamos de Sintaxis estamos refiriéndonos, en escencia, a un Script.\nImaginen que un Script es como una hoja de receta de cocina, allí anotamos todos los ingredientes, fases y procedimientos que debemos seguir e ir ejecutando. Esta receta la podemos compartir con otros, volver a verla cuando queramos hacer lo mismo o algo similar. Esa es la gracia de un Script.\nSi bien podemos escribir y ejecutar código directamente en la consola, estos se eliminarán una vez que cerremos la sesión en RStudio.\n¿Cómo crear un Script? Hacerlo es bastante sencillo. En la sección superior izquierda de RStudio, debe hacerse click en la hoja con un signo + verde y, luego, seleccionar la opción R Script en el menú desplegado:\n\n\n\n\n\n\n\n\n\nOtra manera de abrir un nuevo script es hacer click en la opción File de la barra superior. Posteriormente seleccionar New File > R Script en los menús desplegados:\n\n\n\n\n\n\n\n\n\nPor último, podemos mantener presionadas las teclas Ctrl + Shift + N en Windows, o ⌘ + Shift + N en Mac.\n¡Hemos abierto un nuevo script¡, que se debe ver de la siguiente manera:\n\n\n\n\n\n\n\n\n\nPodemos escribir en él los códigos, que se ejecutarán en la consola una vez mantengamos presionadas las teclas Control + Enter al inicio de la línea\n\n\n\n\n\n\n\n\n\n¿Y cómo guardo mi código? Podemos hacer click en el disquete situado en la barra que se encuentra sobre el código, o bien, apretar Ctrl + S.\n\n\n\n\n\n\n\n\n\nLa primera vez que guardemos un Script, nos pedirá que le asignemos un nombre y una ruta donde guardarlo. Este nombre debe ser sustantivo (como procesamiento o análisis), y debemos alojarlo en las subcarpetas que creamos en el paso anterior. Generalmente, guardaremos los scripts en la carpeta de Procesamiento. En este ejemplo, lo llamaremos script01:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUna vez almacenado en una carpeta, cada vez que clickeemos en los casetes o mantengamos presionadas las teclas Control + S, el archivo se actualizará a la última versión que hayamos guardado\n\n\n\nHoy aprendimos a procesar datos en R. En detalle, vimos:\n\nCómo establecer un flujo de trabajo mediante scripts y Rprojects siguiendo el protocolo IPO\nCómo crear un proyecto de R (R.proyect)\nCómo crear un script (hoja) en R\n\n\n\n\n\n Presentación Sesión 1.pdf"
  },
  {
    "objectID": "content/02-content.html",
    "href": "content/02-content.html",
    "title": "Práctica 2. Conocimientos básicos de programación en R",
    "section": "",
    "text": "El objetivo de esta guía práctica es introducirnos en los procedimientos básicos del uso del lenguaje y ambiente R.\nEn detalle, aprenderemos:\n\nHerramientas básicas de programación en R\nOperadores en R\nTipos de datos\n\n\n\n\nRevisemos algunos conocimientos básicos para la programación en R. Pero antes, tengamos dos cosas en mente:\n\nPrimero, ¿qué es codificar?, en programación codificar corresponde a un proceso de entrega de instrucciones en un lenguaje específico, siguiendo un orden lógico y coherente.\nSegundo, de aquí en adelante nos manejaremos con una máxima en el curso; existe un acuerdo implícito entre tú y R: R hará todos los cálculos por ti, pero en cambio tú debes dar las instrucciones con total precisión.\n\n\n\nUno de los usos más sencillos y que están a la base de R, es usarlo como una calculadora.\n\n5+5\n\n[1] 10\n\n25/5\n\n[1] 5\n\n2*2\n\n[1] 4\n\n27-2\n\n[1] 25\n\n\nComo podrás ver, el resultado de estas instrucciones aparecen como un [1] en la consola. También podemos hacer operatorias más complejas y con más cálculos.\n\n12*(7+2)+(45-32)+8\n\n[1] 129\n\n22^2 - 2^2\n\n[1] 480\n\n1/200 * 30\n\n[1] 0.15\n\n\n\n\n\nR es un lenguaje de programación orientado a objetos. ¿Qué significa eso?, implica que podemos crear elementos dentro del ambiente de R, a los cuales les asignaremos información que quedará almacenada, información que puede ir desde números, palabras, cálculos hasta grandes bases de datos.\nTodas las instrucciones en R en las que crees objetos, es decir, instrucciones de asignación, tendrán la misma estructura:\nnombre_objeto <- valor\nEl asignador <- se utiliza para crear objetos y forma parte de uno de los operadores usados en R.\nLos elementos que podemos asignar a objetos son múltiples, como números, palabras acompañadas siempre de corchetes \" \" y vectores que corresponden a un conjunto o secuencia de elementos del mismo tipo definidos por la funcion de concatenar = c().\nVeamos un ejemplo creando objetos:\n\nx <- 4 # asignar\n\nx # ejecutar\n\n[1] 4\n\ny <- \"Hola mundo\" # los carácteres alfabéticos siempre van acompañados de corchetes\n\ny \n\n[1] \"Hola mundo\"\n\n\n¿Y concatenando? Hacemos un vector.\n\nedad <- c(18,22,36,19,35) # concatenar (variable de razon)\n\nedad\n\n[1] 18 22 36 19 35\n\ngenero <- c(3,1,1,2,3) # masculino = 1; femenino = 2; transgenero = 3 (variable nominal)\n\ngenero \n\n[1] 3 1 1 2 3\n\ngse <- c(\"ABC1\", \"C2\", \"E\", \"AbC1\", \"E\")  # tambíen se pueden usar carácteres (variable ordinal)\n\ngse\n\n[1] \"ABC1\" \"C2\"   \"E\"    \"AbC1\" \"E\"   \n\n\n¡Hagamos una pequeño reto!: ¿Cuál es el valor de a y b? Si a <- 5; b <- a; a <- 4\n\na <- 5\nb <- a\na <- 4\n\nprint(a) # imprimir en la consola\n\n[1] 4\n\nprint(b)\n\n[1] 5\n\na + 10\n\n[1] 14\n\n\nAhora, sea z = a^2 ¿qué resultado obtenemos de a * b + z?\n\nz <- a^2 # asignar\n\na * b + z\n\n[1] 36\n\n\nAdemás de lo anterior, en R es fundamental la creación de data.frames. Un Data.frame es una estructura de datos de dos dimensiones (columnas y filas), donde las columnas pueden ser de diferente naturaleza, pero deben tener el mismo largo. A partir de ella agrupamos variables en una matriz, o sea, construimos una base de datos. Es como “pegar” las columnas (variables) una al lado de otra.\nCreemos un data.frame con los vectores que ya creamos antes.\n\nbase1 <- data.frame(genero, gse, edad) # Resulta como objeto de \"datos\" en\n                                       # entorno.\n\nbase1\n\n  genero  gse edad\n1      3 ABC1   18\n2      1   C2   22\n3      1    E   36\n4      2 AbC1   19\n5      3    E   35\n\n\nComo puedes ver, para crear el data.frame usamos la función que lleva el mismo nombre, colocando dentro del paréntesis los vectores que creamos anteriormente: data.frame(mis_vectores).\nAhora, creemos un data.frame desce cero. En este ejemplo, crearemos los vectores dentro de la función data.frame().\n\n# Ejemplo de como crear un data.frame desde 0: \n\nbase2 <- data.frame(Sexo=c(\"H\",\"M\",\"H\",\"M\",\"H\",\"M\"),\n                    Estatura=c(1.83,1.76,1.82,1.60,1.90,1.66),\n                    Peso=c(67,58,66,48,75,55))\n\nhead(base2)  # Me permite visualizar las primeras filas\n\n  Sexo Estatura Peso\n1    H     1.83   67\n2    M     1.76   58\n3    H     1.82   66\n4    M     1.60   48\n5    H     1.90   75\n6    M     1.66   55\n\n\n\n\n\n\nAntes de trabajar con datos, debemos conocer el concepto de operadores. Estos símbolos no son de uso exclusivo en R, pero no todos tienen el mismo significado que en otros softwares.\nLos operadores son símbolos que permiten, en los distintos procedimientos de procesamiento, simplificar procesos. Por ejemplo, serán útilizados cuando filtremos nuestros datos para personas de ciertas categorías, cuando calculemos variables nuevas (de manera aritmética o condicional) o, simplemente, cuando queramos hacer procesos “concatenados”.\n\n¡Veamos algunos ejemplos!\n\n20 == 5 # igualdad\n\n[1] FALSE\n\n30 >= 14 # mayor o igual que\n\n[1] TRUE\n\n22 <= 2 # menor o igual que\n\n[1] FALSE\n\n25 != 10 # no es igual a\n\n[1] TRUE\n\np = 10; y = 5; p <= y # operatoria en objetos\n\n[1] FALSE\n\n\n\n\n\n\n\nEn R, al igual que en la mayoría de lenguajes de programación, contamos con datos de diversos tipos, en razón de los cuales podemos realizar determinados procedimientos de tratamiento o análisis.\nLos tipos de datos están íntimamente relacionados con el nivel de medición de las variables a las que corresponden. Como viste en clases, la teoría de los niveles de medición contempla cuatro tipos:\n\n\n\n\nPara responder esta pregunta, ¡metamos nuestras manos en los datos!. En esta oportunidad trabajaremos sobre un subset de datos del Modulo de Desigualdad Social de la encuesta International Social Survey Programme del 2019. Esta base la descargaremos directamente desde internet por esta vez (en futuras sesiones aprenderemos cómo cargar bases de datos).\n\n#cargamos la base de datos desde internet\n\nload(url(\"https://github.com/Andreas-Lafferte/descriptiva/blob/main/data/db-proc.RData?raw=true\"))\n\nhead(rand_df) # ver primeros casos de la base\n\n       pais edad   sexo          ideologia percepcion_conflictos\n1     Suiza   23 Hombre          Izquierda                     2\n2     Chile   27  Mujer Sin identificación                     2\n3     Rusia   43  Mujer Sin identificación                     1\n4 Finlandia   71  Mujer Sin identificación                     1\n5     Japon   54  Mujer          Izquierda                     2\n6  Lituania   67  Mujer Sin identificación                     1\n\n\n\n\nLos datos character están directamente asociados a las variables cualitativas (o categóricas). Generalmente suelen ser variables de texto abierto, como es el caso de la variable pais, que detalla el país de procedencia de la persona encuestada.\nPara conocer cuál es el tipo de variable en R, utilizamos el comando class(), y para detallar dentro de la base de datos cuál es la variable de interés, utilizamos el símbolo $ posterior a la base de datos:\n\nclass(rand_df$pais) # siempre es la misma estructura = base$variable\n\n[1] \"character\"\n\n\nSin embargo, estas variables no tienden a ser las mejores a la hora de presentar nuestros resultados. Como solución, tenemos las variables de tipo Factor.\n\n\n\nLas variables de tipo factor son ideales para trabajar con variables de tipo nominal u ordinal. Esto es así debido a que permiten establecer un orden entre las categorías de la variable, lo cual es fundamental si trabajamos, por ejemplo, con variables nominales como el sexo de los encuestados, o si trabajamos con variables ordinales como su ideología política.\n\nclass(rand_df$sexo)\n\n[1] \"factor\"\n\nclass(rand_df$ideologia)\n\n[1] \"factor\"\n\n\n\n\n\nLas variables de tipo numeric son variables de tipo númerica, las cuales pueden ser intervales o de razón. Así, por ejemplo, cuando trabajamos con variables de razón trabajamos con variables como el número de hijos o la edad (aunque sería extraño encuestar a alguien con 0 años).\n\nclass(rand_df$edad)\n\n[1] \"numeric\""
  },
  {
    "objectID": "content/02-content.html#video-de-clase",
    "href": "content/02-content.html#video-de-clase",
    "title": "Práctica 2. Conocimientos básicos de programación en R",
    "section": "Video de clase",
    "text": "Video de clase"
  },
  {
    "objectID": "content/03-content.html",
    "href": "content/03-content.html",
    "title": "Práctica 3. Procesamiento, limpieza y manipulación de datos en R",
    "section": "",
    "text": "El objetivo de esta guía práctica es revisar algunos procedimientos básicos de la preparación de datos con R, los cuales son necesarios para luego poder aplicar los contenidos más específicos de este curso.\nEn detalle, aprenderemos:\n\nEstablecer un flujo de trabajo ordenado en un script (.R).\nInstalar y cargar paquetes y librerías, así como también leer bases de datos en R.\nLimpiar, transformar y exportar bases de datos en R.\n\n¡Al final de esta práctica la idea es que cada un_ elabore y entienda su propio documento de preparación de datos!\n\n\n\nEn esta práctica trabajaremos con un subset de los datos del Estudio Longitudinal Social de Chile (ELSOC) realizado por COES. Esta base la pueden encontrar en el canal de U-Cursos sección Material Docente, o bien, en el siguiente enlace  ELSOC 2022 podrán descargar el archivo que contiene la base ELSOC 2022.\nRecuerden que siempre es importante trabajar con el manual/libro de códigos de las bases de datos. El manual de la ELSOC 2022 lo pueden encontrar aquí.\n\n\n\nPor temas de orden y reproducibilidad, en este curso vamos a separar en dos momentos el trabajo con datos, y dos archivos de código correspondientes:\n\nPreparación: corresponde a lo que se conoce generalmente como “limpieza”, es decir, realizar las modificaciones necesarias a los datos para poder efectuar los análisis. Estas modificaciones previas al análisis son necesarias ya que los datos originales con los que se va a trabajar en general no vienen perfectamente adaptados a los análisis que se quieren hacer. Por lo tanto, en cuanto a datos también hacemos la distinción entre datos originales y datos preparados (o procesados).\nAnálisis: se relaciona con análisis estadísticos, en este caso descriptivos, asociados a las preguntas e hipótesis de investigación.\n\nLos procesos de preparación y análisis vinculados tanto a datos y resultados se presentan en el siguiente esquema:\n\nTanto la preparación como el análisis (que son parte del concepto más general de procesamiento) quedan registrados cada uno en un archivo de código respectivo.\nEn esta guía nos centraremos en la preparación de datos con R. El documento de código de preparación tiene, por lo menos, 4 partes más una sección de identificación inicial:\n\nIdentificación y descripción general: Título, autor(es), fecha, información breve sobre el contenido del documento\nLibrerías: instalar/cargar librerías a utilizar\nDatos: carga de datos\nProcesamiento: limpiar y transformar datos\nGuardar y exportar: generación de base de datos preparada para el análisis\n\nEn la práctica, tu script debería (ojalá siempre) verse así:"
  },
  {
    "objectID": "content/03-content.html#cargar-librerías",
    "href": "content/03-content.html#cargar-librerías",
    "title": "Práctica 3. Procesamiento, limpieza y manipulación de datos en R",
    "section": "1 Cargar librerías",
    "text": "1 Cargar librerías\nEn R se trabaja a partir de paquetes (packages). ¿Qué son? De forma resumida, los paquetes son un conjunto de funciones o herramientas que pueden ser usadas en R. Los directorios de R donde se almacenan los paquetes se denominan librerías. La lógica es instalar paquetes y luego cargar (o llamar) las librerías cada vez que es necesario usarlas.\nUsualmente para cargar paquetes lo hacemos de la siguiente manera:\n\ninstall.packages(\"paquete\")\nlibrary(paquete)\n\nPero en esta ocasión utilizaremos un paquete llamado pacman, que facilita y agiliza la lectura (instalación y carga) de los paquetes a utilizar en R. De esta forma lo instalamos 1 única vez así:\n\ninstall.packages(\"pacman\")\nlibrary(pacman)\n\nLuego instalaremos y cargaremos los paquetes de R de la siguiente manera, volviendo más eficiente el procedimiento de carga de paquetes.\nEn este práctico utilizaremos seis paquetes\n\npacman: este facilita y agiliza la lectura de los paquetes a utilizar en R\ntidyverse: colección de paquetes, de la cual utilizaremos dplyr y haven\ndplyr: nos permite seleccionar variables de un set de datos\nhaven: cargar y exportar bases de datos en formatos .sav y .dta\ncar: para recodificar/agrupar valores de variables\nmagrittr: para manipular datos con %>%\n\n\npacman::p_load(tidyverse, # colección de paquetes para manipulación de datos\n               dplyr, # para manipular datos\n               haven, # para importar datos\n               car, # para recodificar datos\n               magrittr)# para manipular datos\n\noptions(scipen = 999) # para desactivar notacion cientifica\nrm(list = ls()) # para limpiar el entorno de trabajo\n\nComo se puede ver, antes de la función p_load hay un ::, esto se refiere a que se “fuerza” que esa función provenga de ese paquete (en este caso del paquete pacman)."
  },
  {
    "objectID": "content/03-content.html#importar-datos",
    "href": "content/03-content.html#importar-datos",
    "title": "Práctica 3. Procesamiento, limpieza y manipulación de datos en R",
    "section": "2 Importar datos",
    "text": "2 Importar datos\nEn R es es posible importar y exportar datos que se encuentren en cualquier formato: ya sea .csv, .dta, .sav, .xlsx y, por supuesto, .rds y .RData. Sin embargo, para poder hacerlo lo primero es instalar y cargar las librerías que contienen las funciones necesarias para la importación de distintos tipos de archivos.\nPero, ¿dónde están mis datos? Como hemos mencionado, nuestros datos los dejaremos en la carpeta input/data de nuestro proyecto. La base con la que trabajaremos en este práctico pueden encontrarla en el material docente en U-Cursos, o bien, en el siguiente enlace.\nLuego de descargar la base de datos, asegurate de dejar el archivo .sav en la carpeta input/data de tu proyecto. Nota: Los datos tendrán distinto nombre según su formato (.sav, .csv, .dta, etc.).\nUna vez descargados los datos y cargado el paquete haven, procedemos a importar nuestra base de datos. Para ello, en nuestro script, dejamos indicado que a partir de la lectura de los datos con read_sav(), crearemos un objeto llamado elsoc_2022. Fijate en el Enviroment, ya que si lo anterior se logra, el objeto aparecerá allí.\nLa estructura general para importar datos es la siguiente:\nread_*(\"ruta_hacia_archivo/nombre_archivo.*\")\n\nelsoc_2022 <- read_sav(\"ELSOC W06 v1.0 SPSS.sav\")  # No funciona\n\nelsoc_2022 <- read_sav(\"input/data/ELSOC W06 v1.0 SPSS.sav\") # No funciona\n\nelsoc_2022 <- read_sav(\"input/data/ELSOC_W06_v1.0_SPSS.sav\") # Si funciona!\n\n\n\n\n\n\n\nNota\n\n\n\nPara importar los datos en R debemos tener en consideración tres cosas:\n\nCómo se llaman los datos (en nuestro caso ELSOC_W05_v1.0_SPSS)\nEl formato de nuestros datos (en nuestro caso .sav)\nEl lugar de donde están alojados nuestros datos\n\n\n\n\n2.1.1 Importar datos en otros formatos\nNo siempre nuestros datos vendrán en un único formato. Para ello, R cuenta con otras formas de leer distintos tipos de formatos. Puedes ver las principales en el siguiente enlace."
  },
  {
    "objectID": "content/03-content.html#explorar-datos",
    "href": "content/03-content.html#explorar-datos",
    "title": "Práctica 3. Procesamiento, limpieza y manipulación de datos en R",
    "section": "3 Explorar datos",
    "text": "3 Explorar datos\nLo más probable es que no trabajemos con todos los datos que importamos, por lo que debemos seleccionar aquellas variables con las que trabajaremos para nuestro problema de investigación (cualquiera sea).\nPero, para ello primero debemos explorar nuestros datos, si no ¿cómo puedo saber qué seleccionar y qué no? En R, las funciones más comunes para explorar datos son:\n\nView(elsoc_2022) # Ver datos\nnames(elsoc_2022) # Nombre de columnas\ndim(elsoc_2022) # Dimensiones\nstr(elsoc_2022) # Estructura de los datos (las clases y categorias de repuesta)\n\nTenemos una base de datos con 1000 casos o filas y con 13 variables o columnas."
  },
  {
    "objectID": "content/03-content.html#limpiar-datos",
    "href": "content/03-content.html#limpiar-datos",
    "title": "Práctica 3. Procesamiento, limpieza y manipulación de datos en R",
    "section": "4 Limpiar datos",
    "text": "4 Limpiar datos\nPara todos los subprocesos que involucra la “limpieza” de datos, tenemos al menos dos maneras. Por un lado, podemos usar las funciones de R base, es decir, que no requieren paquetes extras. Por el otro, podemos usar las funciones del paquete dplyr(), que es una gramática o dialecto de manipulación de datos que proporciona un conjunto de coherente funciones o “verbos” básicos para programar.\n\n\n\n\n\n\n\n\n\nPero, ¿por qué gramática y verbos? Porque a diferencia de otras formas de programar, dplyr() está orientado a escribir código como la escritura normal, es decir, de izquierda a derecha. Generalmente, la estructura de dplyr() es:\ndplyr::funcion(datos, variable1, variable2, variable_n)\nEn este práctico solo nos centraremos en manipular datos con dplyr(). Para conocer cómo hacer lo mismo pero con R base visita este enlace.\n\n\n4.1 Seleccionar\nUna vez tenemos claras cúales son las variables que nos interesan, las seleccionamos y almacenamos en una nueva base de datos. Esto debido que evitará confusiones y hará más eficiente nuestros analísis en términos de memoria.\nEn R base, el primer argumento dentro del bracket [] refiere a las filas y el segundo a las columnas. De manera similar, la función select() de dplyr facilita el trabajo a la hora de seleccionar variables. La estructura general del comando siempre es select(datos, variable1, variable2, variable3).\nHay distintas formas de usar select(), ¡veámoslas!\nPor indexación o ubicación en la base de datos:\n\ndplyr::select(elsoc_2022, 1, 2) # la primera y la segunda columna\n\ndplyr::select(elsoc_2022, 1:4) # la primera hasta la cuarta columna\n\ndplyr::select(elsoc_2022, c(1, 4, 5)) # la primera, la cuarta y la quinta columna\n\nTambién podemos usar el nombre de la variable/columna. Si conocemos el nombre de la variable simplemente lo podemos poner y se seleccionará. Con select() no es necesario poner los nombres con comillas \" \":\n\ndplyr::select(elsoc_2022, m0_sexo, m0_edad, m13)\n\n# A tibble: 1,000 × 3\n   m0_sexo m0_edad     m13\n   <chr>     <dbl>   <dbl>\n 1 Hombre       38 4000000\n 2 Mujer        45 2700000\n 3 Hombre       42  600000\n 4 Hombre       29 1250000\n 5 Mujer        53  500000\n 6 Mujer        52      NA\n 7 Mujer        50      NA\n 8 Mujer        57       0\n 9 Mujer        47  600000\n10 Hombre       79      NA\n# … with 990 more rows\n\n\nOtra cosa que podemos hacer es renombrar las variables al momento de seleccionarlas, para que tengan un sentido más sustantivo para nosotros.\n\ndplyr::select(elsoc_2022, sexo = m0_sexo, edad = m0_edad, ingreso = m13)\n\n# A tibble: 1,000 × 3\n   sexo    edad ingreso\n   <chr>  <dbl>   <dbl>\n 1 Hombre    38 4000000\n 2 Mujer     45 2700000\n 3 Hombre    42  600000\n 4 Hombre    29 1250000\n 5 Mujer     53  500000\n 6 Mujer     52      NA\n 7 Mujer     50      NA\n 8 Mujer     57       0\n 9 Mujer     47  600000\n10 Hombre    79      NA\n# … with 990 more rows\n\n\nPor último, podemos usar select() para reordenar nuestras variables, lo cual es importante por si por ejemplo utilizamos variables de identificación.\n\ndplyr::select(elsoc_2022, m0_edad, m0_sexo, c25, m13)\n\n# A tibble: 1,000 × 4\n   m0_edad m0_sexo   c25     m13\n     <dbl> <chr>   <dbl>   <dbl>\n 1      38 Hombre      1 4000000\n 2      45 Mujer       1 2700000\n 3      42 Hombre      3  600000\n 4      29 Hombre      1 1250000\n 5      53 Mujer       2  500000\n 6      52 Mujer       3      NA\n 7      50 Mujer       2      NA\n 8      57 Mujer       1       0\n 9      47 Mujer       1  600000\n10      79 Hombre      2      NA\n# … with 990 more rows\n\n\nAhora, ¡apliquemos conocimientos! seleccionando y renombrando las variables de interés en un nueva base llamada proc_elsoc.\nEn este ejemplo utilizaremos las siguientes variables:\n\nm0_sexo: sexo del entrevistado\nm0_edad: edad del entrevistado\nm13: ingreso mensual entrevistado\nc25: preferencia entre autoritarismo y democracia\nf05_01: justificación violencia hacia delincuentes\n\n\nproc_elsoc <- dplyr::select(elsoc_2022, \n                            edad = m0_edad,\n                            sexo = m0_sexo,\n                            ingreso = m13,\n                            autor_democ = c25,\n                            jv_delincuentes = f05_01)\n\nproc_elsoc\n\n# A tibble: 1,000 × 5\n    edad sexo   ingreso autor_democ jv_delincuentes\n   <dbl> <chr>    <dbl>       <dbl>           <dbl>\n 1    38 Hombre 4000000           1              NA\n 2    45 Mujer  2700000           1               3\n 3    42 Hombre  600000           3              NA\n 4    29 Hombre 1250000           1               1\n 5    53 Mujer   500000           2               3\n 6    52 Mujer       NA           3               2\n 7    50 Mujer       NA           2               5\n 8    57 Mujer        0           1               4\n 9    47 Mujer   600000           1               3\n10    79 Hombre      NA           2               1\n# … with 990 more rows\n\n\nEsta nueva base de datos sigue manteniendo los 1.000 casos/filas, pero ahora solo tiene 5 variables/columnas. ¿Qué pasa si solo quiero trabajar con un subconjunto de estos datos, por ejemplo, las mujeres mayores a 25 años? La respuesta es filtrar.\n\n\n4.2 Filtrar\nTal y como regularmente no trabajamos con todas las variables de una base de datos, no siempre desearemos trabajar con todas las observaciones que tenemos en los datos. Habrá ocasiones (varias) en las que querremos trabajar con casos que cumplan ciertas condiciones; que sean de determinada edad, residencia, tiempo o que simplemente hayan respondido de determinada forma una pregunta.\nCon dplyr podemos filtrar nuestros datos con el comando filter(), en el cual debemos especificar los datos y las condiciones que queremos aplicarle a determinadas variables.\n\ndplyr::filter(proc_elsoc, autor_democ == 1)\n\n# A tibble: 552 × 5\n    edad sexo   ingreso autor_democ jv_delincuentes\n   <dbl> <chr>    <dbl>       <dbl>           <dbl>\n 1    38 Hombre 4000000           1              NA\n 2    45 Mujer  2700000           1               3\n 3    29 Hombre 1250000           1               1\n 4    57 Mujer        0           1               4\n 5    47 Mujer   600000           1               3\n 6    39 Hombre 1350000           1               4\n 7    61 Mujer       NA           1               3\n 8    25 Hombre      NA           1               2\n 9    42 Hombre 1100000           1               4\n10    51 Hombre  800000           1               1\n# … with 542 more rows\n\n\nPara indicarle a R que nos filtre aquellos casos que cumplen con la condición de ser iguales a 1 (autor_democ == 1), usamos el operador ==. ¿Y esto de dónde salió? recuerda que los operadores en R los vimos en la segunda sesión\nTambién podemos agregar muchas condiciones para filtrar nuestros datos. Solamente debemos agregarlo, usando los operadores relacionales de R.\n\ndplyr::filter(proc_elsoc, autor_democ == 1 & edad >= 25)\n\n# A tibble: 544 × 5\n    edad sexo   ingreso autor_democ jv_delincuentes\n   <dbl> <chr>    <dbl>       <dbl>           <dbl>\n 1    38 Hombre 4000000           1              NA\n 2    45 Mujer  2700000           1               3\n 3    29 Hombre 1250000           1               1\n 4    57 Mujer        0           1               4\n 5    47 Mujer   600000           1               3\n 6    39 Hombre 1350000           1               4\n 7    61 Mujer       NA           1               3\n 8    25 Hombre      NA           1               2\n 9    42 Hombre 1100000           1               4\n10    51 Hombre  800000           1               1\n# … with 534 more rows\n\n\nPero, ¿y si tengo variables tipo character o factor? Tanto en R base como con dplyr podemos especificar condiciones y filtrar este tipo de datos usando las comillas \" \".\n\ndplyr::filter(proc_elsoc, sexo == \"Mujer\")\n\n# A tibble: 656 × 5\n    edad sexo  ingreso autor_democ jv_delincuentes\n   <dbl> <chr>   <dbl>       <dbl>           <dbl>\n 1    45 Mujer 2700000           1               3\n 2    53 Mujer  500000           2               3\n 3    52 Mujer      NA           3               2\n 4    50 Mujer      NA           2               5\n 5    57 Mujer       0           1               4\n 6    47 Mujer  600000           1               3\n 7    61 Mujer      NA           1               3\n 8    78 Mujer      NA           4               1\n 9    65 Mujer      NA           1               1\n10    69 Mujer      NA           2               1\n# … with 646 more rows\n\n\n¡Apliquémos conocimientos! Filtremos nuestros datos quedándonos solo con aquellos casos o personas que tengan o sean mayores a 25 años de edad.\n\nproc_elsoc <- dplyr::filter(proc_elsoc, edad >= 25)\n\nproc_elsoc\n\n# A tibble: 980 × 5\n    edad sexo   ingreso autor_democ jv_delincuentes\n   <dbl> <chr>    <dbl>       <dbl>           <dbl>\n 1    38 Hombre 4000000           1              NA\n 2    45 Mujer  2700000           1               3\n 3    42 Hombre  600000           3              NA\n 4    29 Hombre 1250000           1               1\n 5    53 Mujer   500000           2               3\n 6    52 Mujer       NA           3               2\n 7    50 Mujer       NA           2               5\n 8    57 Mujer        0           1               4\n 9    47 Mujer   600000           1               3\n10    79 Hombre      NA           2               1\n# … with 970 more rows\n\n\n\n\n4.3 Recodificar\nUna parte fundamental del procesamiento e integración de datos es la recodificación de variables. Esto implica que, a determinadas variables, le aplicaremos ciertos cambios de acuerdo a ciertas reglas y criterios establecidos con anterioridad, siempre cuidando la coherencia con nuestro objetivo de investigación.\nHay múltiples formas de recodificar en R, pero en este ejemplo trabajaremos con el comando recode() del paquete car.\nEsta vez, recodificaremos las siguientes variables: sexo, ingreso, autor_democ y jv_delincuentes. Para esto, nos apoyaremos en el libro de códigos.\n\n\n\n\n\n\nTip\n\n\n\nEl comando recode() generalmente sigue esta estructura:\ncar::recode(datos$variable, recodes = c('valor_orig1=nuevo_valor1;valor_org2=nuevo_valor2'))\n\n\nA diferencia de R base, con la función mutate() de dplyr podemos recodificar todas nuestras variables en un solo código si así lo queremos. Además, nos ahorramos especificar en todo momento la base de datos, ya que esa es la lógica de programación con dplyr().\nLa estructura de mutate() es generalmente esta:\ndplyr::mutate(datos, nueva_variable = funcion())\nRecodifiquemos las variables sexo e ingresos:\n\nproc_elsoc <- dplyr::mutate(proc_elsoc,\n                            sexo = car::recode(sexo,\n                                               recodes = c(\"'Hombre' = 'Masculino'; 'Mujer' = 'Femenino'\")),\n                            ingreso = car::recode(ingreso, \n                                                  recodes = c(\"-888 = NA; -999 = NA\")))\n\n\nproc_elsoc\n\n# A tibble: 980 × 5\n    edad sexo      ingreso autor_democ jv_delincuentes\n   <dbl> <chr>       <dbl>       <dbl>           <dbl>\n 1    38 Masculino 4000000           1              NA\n 2    45 Femenino  2700000           1               3\n 3    42 Masculino  600000           3              NA\n 4    29 Masculino 1250000           1               1\n 5    53 Femenino   500000           2               3\n 6    52 Femenino       NA           3               2\n 7    50 Femenino       NA           2               5\n 8    57 Femenino        0           1               4\n 9    47 Femenino   600000           1               3\n10    79 Masculino      NA           2               1\n# … with 970 more rows\n\n\nAhora recodifiquemos las demás variables. Además de recodificar valores propiamente tal, con recode() podemos indicarle, en la misma función, que convierta la variable a factor y/o que le asigne niveles (ej. para variables ordinales).\n\nproc_elsoc <- dplyr::mutate(proc_elsoc,\n                            autor_democ = car::recode(autor_democ,\n                            recodes = c(\"1 = 'La democracia es preferible a cualquier otra forma de gobierno'; \n                            2 = 'En algunas circunstancias, un gobierno autoritario puede ser preferible a uno democratico'; \n                            3 = 'A la gente como uno, nos da lo mismo un regimen democratico que uno autoritario'; \n                            4 = 'Ninguna'; \n                            -888 = NA; \n                            -999 = NA\"),\n                            as.factor = TRUE)) # convertir a factor\n            \nproc_elsoc <- dplyr::mutate(proc_elsoc,\n                            jv_delincuentes = car::recode(jv_delincuentes,\n                                            recodes = c(\"1 = 'Nunca';\n                                                       2 = 'Pocas veces';\n                                                       3 = 'Algunas veces';\n                                                       4 = 'Muchas veces';\n                                                       5 = 'Siempre';\n                                                       -888 = NA; \n                                                       -999 = NA\"),\n                                          as.factor = TRUE, # convertir a factor\n                                          levels = c(\"Nunca\",\n                                                     \"Pocas veces\",\n                                                     \"Algunas veces\",\n                                                     \"Muchas veces\",\n                                                     \"Siempre\")))# ordenamos niveles\n  \nproc_elsoc\n\n# A tibble: 980 × 5\n    edad sexo      ingreso autor_democ                                   jv_de…¹\n   <dbl> <chr>       <dbl> <fct>                                         <fct>  \n 1    38 Masculino 4000000 La democracia es preferible a cualquier otra… <NA>   \n 2    45 Femenino  2700000 La democracia es preferible a cualquier otra… Alguna…\n 3    42 Masculino  600000 A la gente como uno, nos da lo mismo un regi… <NA>   \n 4    29 Masculino 1250000 La democracia es preferible a cualquier otra… Nunca  \n 5    53 Femenino   500000 En algunas circunstancias, un gobierno autor… Alguna…\n 6    52 Femenino       NA A la gente como uno, nos da lo mismo un regi… Pocas …\n 7    50 Femenino       NA En algunas circunstancias, un gobierno autor… Siempre\n 8    57 Femenino        0 La democracia es preferible a cualquier otra… Muchas…\n 9    47 Femenino   600000 La democracia es preferible a cualquier otra… Alguna…\n10    79 Masculino      NA En algunas circunstancias, un gobierno autor… Nunca  \n# … with 970 more rows, and abbreviated variable name ¹​jv_delincuentes\n\n\n\n\n\n\n\n\nNota\n\n\n\nComo se puede ver, los valores -888 y -999 fueron codificados como valores pérdidos ya que estos valores significan no sabe y no responde, respectivamente.\n\n\n\n\n4.4 Tratamiento casos pérdidos\nComúnmente, los datos con los que trabajamos suelen tener valores pérdidos o nulos que en R se denominan como NA. Estos valores no nos entregan información útil para nuestros análisis, y pueden generar problemas al momento de, por ejemplo, calcular medidas de tendencia central, u otros procedimientos estadísticos.\nHay diversas maneras de trabajar los valores nulos. Sin embargo, la más sencilla consiste en eliminar los valores nulos que se encuentran presentes en nuestros datos.\nEl primer paso es identificar valores nulos en el conjunto de datos en general, o en alguna variable en específico. Para ello, empleamos la función is.na().\n\nis.na(proc_elsoc)\n\nis.na(proc_elsoc$ingreso)\n\nPero esto es poco útil. Como opción, podemos sumar o contar la cantidad de valores pérdidos.\n\nsum(is.na(proc_elsoc))\n\n[1] 515\n\n\n¿Y si no sabemos qué variables o columnas tienen casos pérdidos? Una forma es usar la función colSums().\n\ncolSums(is.na(proc_elsoc))\n\n           edad            sexo         ingreso     autor_democ jv_delincuentes \n              0               0             435              13              67 \n\n\nUna vez identificamos los valores nulos, podemos proceder a removerlos de la base de datos. El comando na.omit() eliminará todas las filas que presenten casos perdidos.\n\nproc_elsoc <- na.omit(proc_elsoc)\n\nproc_elsoc\n\n# A tibble: 496 × 5\n    edad sexo      ingreso autor_democ                                   jv_de…¹\n   <dbl> <chr>       <dbl> <fct>                                         <fct>  \n 1    45 Femenino  2700000 La democracia es preferible a cualquier otra… Alguna…\n 2    29 Masculino 1250000 La democracia es preferible a cualquier otra… Nunca  \n 3    53 Femenino   500000 En algunas circunstancias, un gobierno autor… Alguna…\n 4    57 Femenino        0 La democracia es preferible a cualquier otra… Muchas…\n 5    47 Femenino   600000 La democracia es preferible a cualquier otra… Alguna…\n 6    39 Masculino 1350000 La democracia es preferible a cualquier otra… Muchas…\n 7    42 Masculino 1100000 La democracia es preferible a cualquier otra… Muchas…\n 8    51 Masculino  800000 La democracia es preferible a cualquier otra… Nunca  \n 9    38 Masculino 1600000 A la gente como uno, nos da lo mismo un regi… Alguna…\n10    45 Femenino   500000 La democracia es preferible a cualquier otra… Nunca  \n# … with 486 more rows, and abbreviated variable name ¹​jv_delincuentes"
  },
  {
    "objectID": "content/03-content.html#transformar-variables",
    "href": "content/03-content.html#transformar-variables",
    "title": "Práctica 3. Procesamiento, limpieza y manipulación de datos en R",
    "section": "5 Transformar variables",
    "text": "5 Transformar variables\nUn último paso en el procesamiento de datos es la creación o derivación de nuevas variables a partir de los datos que ya tenemos. Esto es relevante no solo para procesar datos, sino porque permite generar variables que se alineen mucho mejor con nuestros objetivos de análisis.\nLa función mutate() de dplyr no solo nos permite recodificar variables, sino que también crear otras nuevas manteniendo las originales. Para este ejemplo usaremos dos funciones adicionales de dplyr que, al combinarlas con mutate(), podremos transformar variables de manera muy sencilla.\nEn este ejemplo, transformaremos las variables edad e ingresos, y crearemos una nueva variable llamada año de la encuesta y otra llamada ingreso_minimo.\n¡Veámos cómo se hace!\nGeneremos las nueva variable año:\n\nproc_elsoc <- mutate(proc_elsoc, ano = 2022)\n\nproc_elsoc\n\n# A tibble: 496 × 6\n    edad sexo      ingreso autor_democ                             jv_de…¹   ano\n   <dbl> <chr>       <dbl> <fct>                                   <fct>   <dbl>\n 1    45 Femenino  2700000 La democracia es preferible a cualquie… Alguna…  2022\n 2    29 Masculino 1250000 La democracia es preferible a cualquie… Nunca    2022\n 3    53 Femenino   500000 En algunas circunstancias, un gobierno… Alguna…  2022\n 4    57 Femenino        0 La democracia es preferible a cualquie… Muchas…  2022\n 5    47 Femenino   600000 La democracia es preferible a cualquie… Alguna…  2022\n 6    39 Masculino 1350000 La democracia es preferible a cualquie… Muchas…  2022\n 7    42 Masculino 1100000 La democracia es preferible a cualquie… Muchas…  2022\n 8    51 Masculino  800000 La democracia es preferible a cualquie… Nunca    2022\n 9    38 Masculino 1600000 A la gente como uno, nos da lo mismo u… Alguna…  2022\n10    45 Femenino   500000 La democracia es preferible a cualquie… Nunca    2022\n# … with 486 more rows, and abbreviated variable name ¹​jv_delincuentes\n\n\n\nTransformar variables con case_when() e if_else()\nGeneremos nuevas variables para edad e ingresos dejándolas como tramos con case_when().\n\nproc_elsoc <- mutate(proc_elsoc,\n                     tramo_edad = case_when(edad <= 29 ~ \"Jovenes\",\n                                            edad >= 30 & edad <= 59 ~ \"Adultos\",\n                                            edad >= 60 ~ \"Adutos mayores\"))\n\n\nproc_elsoc <- mutate(proc_elsoc,\n                     tramo_ingreso = case_when(ingreso <= 250000 ~ \"Tramo 1\",\n                                                ingreso > 250000 & ingreso <= 500000 ~ \"Tramo 2\",\n                                                ingreso > 500000 & ingreso <= 750000 ~ \"Tramo 3\",\n                                                ingreso > 750000 & ingreso <= 1000000 ~ \"Tramo 4\",\n                                                ingreso > 1000000 ~ \"Tramo 5\"))\n\nproc_elsoc\n\n# A tibble: 496 × 8\n    edad sexo      ingreso autor_democ             jv_de…¹   ano tramo…² tramo…³\n   <dbl> <chr>       <dbl> <fct>                   <fct>   <dbl> <chr>   <chr>  \n 1    45 Femenino  2700000 La democracia es prefe… Alguna…  2022 Adultos Tramo 5\n 2    29 Masculino 1250000 La democracia es prefe… Nunca    2022 Jovenes Tramo 5\n 3    53 Femenino   500000 En algunas circunstanc… Alguna…  2022 Adultos Tramo 2\n 4    57 Femenino        0 La democracia es prefe… Muchas…  2022 Adultos Tramo 1\n 5    47 Femenino   600000 La democracia es prefe… Alguna…  2022 Adultos Tramo 3\n 6    39 Masculino 1350000 La democracia es prefe… Muchas…  2022 Adultos Tramo 5\n 7    42 Masculino 1100000 La democracia es prefe… Muchas…  2022 Adultos Tramo 5\n 8    51 Masculino  800000 La democracia es prefe… Nunca    2022 Adultos Tramo 4\n 9    38 Masculino 1600000 A la gente como uno, n… Alguna…  2022 Adultos Tramo 5\n10    45 Femenino   500000 La democracia es prefe… Nunca    2022 Adultos Tramo 2\n# … with 486 more rows, and abbreviated variable names ¹​jv_delincuentes,\n#   ²​tramo_edad, ³​tramo_ingreso\n\n\nAhora, generemos una nueva variable llamada ingreso_minimo con la función if_else().\n\nproc_elsoc <- mutate(proc_elsoc,\n                     ingreso_minimo = if_else(ingreso < 410000, \"debajo minimo\", \"sobre minimo\"))\n\nselect(proc_elsoc, ingreso, ingreso_minimo) #veamosla!\n\n# A tibble: 496 × 2\n   ingreso ingreso_minimo\n     <dbl> <chr>         \n 1 2700000 sobre minimo  \n 2 1250000 sobre minimo  \n 3  500000 sobre minimo  \n 4       0 debajo minimo \n 5  600000 sobre minimo  \n 6 1350000 sobre minimo  \n 7 1100000 sobre minimo  \n 8  800000 sobre minimo  \n 9 1600000 sobre minimo  \n10  500000 sobre minimo  \n# … with 486 more rows"
  },
  {
    "objectID": "content/03-content.html#colocando-todo-en-práctica",
    "href": "content/03-content.html#colocando-todo-en-práctica",
    "title": "Práctica 3. Procesamiento, limpieza y manipulación de datos en R",
    "section": "6 Colocando todo en práctica",
    "text": "6 Colocando todo en práctica\nOtra de las venjatas de dplyr() es que nos permite concatenar funciones siguiendo la misma lógica de programación de izquiera a derecha. Esto lo hacemos a través de los pipes %>%, que es un operador proveniente del paquete magrittr.\nUna función normal es igual a f(x,y), en donde al elemento y del objeto x le aplicamos determinada función f(). Los %>% simplifican funciones y concatenan códigos de la siguiente manera:\nx %>% f(y) es lo mismo que f(x,y).\nEsto significa que el %>% literalmente le dice a R que coloque al objeto x dentro de la función f(), para aplicarle dicha función a y. :::\nVeamos cómo se ocupa y porqué simplifica la vida\n\na) Seleccionemos y filtremos datos con %>%\n\nproc_elsoc <- elsoc_2022 %>% \n  dplyr::select(edad = m0_edad,\n                sexo = m0_sexo,\n                ingreso = m13,\n                autor_democ = c25,\n                jv_delincuentes = f05_01) %>% \n  dplyr::filter(edad >= 25)\n\nproc_elsoc\n\n# A tibble: 980 × 5\n    edad sexo   ingreso autor_democ jv_delincuentes\n   <dbl> <chr>    <dbl>       <dbl>           <dbl>\n 1    38 Hombre 4000000           1              NA\n 2    45 Mujer  2700000           1               3\n 3    42 Hombre  600000           3              NA\n 4    29 Hombre 1250000           1               1\n 5    53 Mujer   500000           2               3\n 6    52 Mujer       NA           3               2\n 7    50 Mujer       NA           2               5\n 8    57 Mujer        0           1               4\n 9    47 Mujer   600000           1               3\n10    79 Hombre      NA           2               1\n# … with 970 more rows\n\n\n\n\nb) Recodifiquemos datos y eliminemos NAs con %>%\n\nproc_elsoc <- proc_elsoc %>% \n  mutate(sexo = car::recode(sexo,\n                            recodes = c(\"'Hombre' = 'Masculino'; 'Mujer' = 'Femenino'\")),\n         ingreso = car::recode(ingreso, \n                               recodes = c(\"-888 = NA; -999 = NA\")),\n         autor_democ = car::recode(autor_democ,\n                                   recodes = c(\"1 = 'La democracia es preferible a cualquier otra forma de gobierno'; \n                            2 = 'En algunas circunstancias, un gobierno autoritario puede ser preferible a uno democratico'; \n                            3 = 'A la gente como uno, nos da lo mismo un regimen democratico que uno autoritario'; \n                            4 = 'Ninguna'; \n                            -888 = NA; \n                            -999 = NA\"),\n                            as.factor = TRUE), # convertir a factor\n         jv_delincuentes = car::recode(jv_delincuentes, \n                                       recodes = c(\"1 = 'Nunca';\n                                                    2 = 'Pocas veces';\n                                                    3 = 'Algunas veces';\n                                                    4 = 'Muchas veces';\n                                                    5 = 'Siempre';\n                                                    -888 = NA; \n                                                   -999 = NA\"),\n                                       as.factor = TRUE, # convertir a factor\n                                       levels = c(\"Nunca\",\n                                                  \"Pocas veces\",\n                                                  \"Algunas veces\",\n                                                  \"Muchas veces\",\n                                                  \"Siempre\"))) %>% \n  na.omit()\n\nproc_elsoc\n\n# A tibble: 496 × 5\n    edad sexo      ingreso autor_democ                                   jv_de…¹\n   <dbl> <chr>       <dbl> <fct>                                         <fct>  \n 1    45 Femenino  2700000 La democracia es preferible a cualquier otra… Alguna…\n 2    29 Masculino 1250000 La democracia es preferible a cualquier otra… Nunca  \n 3    53 Femenino   500000 En algunas circunstancias, un gobierno autor… Alguna…\n 4    57 Femenino        0 La democracia es preferible a cualquier otra… Muchas…\n 5    47 Femenino   600000 La democracia es preferible a cualquier otra… Alguna…\n 6    39 Masculino 1350000 La democracia es preferible a cualquier otra… Muchas…\n 7    42 Masculino 1100000 La democracia es preferible a cualquier otra… Muchas…\n 8    51 Masculino  800000 La democracia es preferible a cualquier otra… Nunca  \n 9    38 Masculino 1600000 A la gente como uno, nos da lo mismo un regi… Alguna…\n10    45 Femenino   500000 La democracia es preferible a cualquier otra… Nunca  \n# … with 486 more rows, and abbreviated variable name ¹​jv_delincuentes\n\n\n\n\nc) Transformemos variables con %>%\n\nproc_elsoc <- proc_elsoc %>% \n  mutate(ano = 2022,\n         tramo_edad = case_when(edad <= 29 ~ \"Jovenes\",\n                                edad >= 30 & edad <= 59 ~ \"Adultos\",\n                                edad >= 60 ~ \"Adutos mayores\"),\n         tramo_ingreso = case_when(ingreso <= 250000 ~ \"Tramo 1\",\n                                   ingreso > 250000 & ingreso <= 500000 ~ \"Tramo 2\",\n                                   ingreso > 500000 & ingreso <= 750000 ~ \"Tramo 3\",\n                                   ingreso > 750000 & ingreso <= 1000000 ~ \"Tramo 4\",\n                                   ingreso > 1000000 ~ \"Tramo 5\"),\n         ingreso_minimo = if_else(ingreso < 410000, \"debajo minimo\", \"sobre minimo\"))\n\nproc_elsoc\n\n# A tibble: 496 × 9\n    edad sexo      ingreso autor_democ     jv_de…¹   ano tramo…² tramo…³ ingre…⁴\n   <dbl> <chr>       <dbl> <fct>           <fct>   <dbl> <chr>   <chr>   <chr>  \n 1    45 Femenino  2700000 La democracia … Alguna…  2022 Adultos Tramo 5 sobre …\n 2    29 Masculino 1250000 La democracia … Nunca    2022 Jovenes Tramo 5 sobre …\n 3    53 Femenino   500000 En algunas cir… Alguna…  2022 Adultos Tramo 2 sobre …\n 4    57 Femenino        0 La democracia … Muchas…  2022 Adultos Tramo 1 debajo…\n 5    47 Femenino   600000 La democracia … Alguna…  2022 Adultos Tramo 3 sobre …\n 6    39 Masculino 1350000 La democracia … Muchas…  2022 Adultos Tramo 5 sobre …\n 7    42 Masculino 1100000 La democracia … Muchas…  2022 Adultos Tramo 5 sobre …\n 8    51 Masculino  800000 La democracia … Nunca    2022 Adultos Tramo 4 sobre …\n 9    38 Masculino 1600000 A la gente com… Alguna…  2022 Adultos Tramo 5 sobre …\n10    45 Femenino   500000 La democracia … Nunca    2022 Adultos Tramo 2 sobre …\n# … with 486 more rows, and abbreviated variable names ¹​jv_delincuentes,\n#   ²​tramo_edad, ³​tramo_ingreso, ⁴​ingreso_minimo"
  },
  {
    "objectID": "content/03-content.html#guardar-y-exportar-datos-procesados",
    "href": "content/03-content.html#guardar-y-exportar-datos-procesados",
    "title": "Práctica 3. Procesamiento, limpieza y manipulación de datos en R",
    "section": "7 Guardar y exportar datos procesados",
    "text": "7 Guardar y exportar datos procesados\n¡Legamos al final! El último paso que nos queda es guardar y exportar nuestra base de datos procesada. Siguiendo el flujo de trabajo propuesto, guardaremos la base procesada en formato .Rdata y la alojaremos en la carpeta output de nuestro proyecto.\nEste último paso es bastante sencillo, solo debemos especificar la base que queremos guadar y su ruta:\n\nsaveRDS(proc_elsoc, file = \"output/datos_proc.Rdata\")"
  },
  {
    "objectID": "content/03-content.html#resumen",
    "href": "content/03-content.html#resumen",
    "title": "Práctica 3. Procesamiento, limpieza y manipulación de datos en R",
    "section": "Resumen",
    "text": "Resumen\nHoy aprendimos a procesar datos en R. En detalle, vimos:\n\nCómo establecer un flujo de trabajo de procesamiento y análisis de datos en R.\nInstalar y cargar paquetes y librerías, así como también leer bases de datos en R.\nLimpiar, transformar y exportar bases de datos en R."
  },
  {
    "objectID": "content/03-content.html#video-de-clase",
    "href": "content/03-content.html#video-de-clase",
    "title": "Práctica 3. Procesamiento, limpieza y manipulación de datos en R",
    "section": "Video de clase",
    "text": "Video de clase\n\nPrimer bloque\n\n\n\nSegundo bloque"
  },
  {
    "objectID": "content/04-content.html",
    "href": "content/04-content.html",
    "title": "Práctica 4. Análisis descriptivo de datos en R",
    "section": "",
    "text": "El objetivo de esta guía práctica es conocer las principales formas de realizar analísis estadísticos descriptivo en R, aplicando los concocimientos aprendidos durante el curso.\nEn detalle, aprenderemos:\n\nEstablecer un flujo de trabajo ordenado en un script (.R).\nAplicar análisis estadísticos descriptivos a variables según su nivel de medición\n\n\n\n\nEn esta práctica trabajeremos con los datos procesados que obtuvimos en la práctica anterior a partir de los datos del Estudio Longitudinal Social de Chile (ELSOC) realizado por COES.\nRecuerden que siempre es importante trabajar con el manual/libro de códigos de las bases de datos. El manual de la ELSOC 2022 lo pueden encontrar aquí.\n\n\n\nPor temas de orden y reproducibilidad, en este curso vamos a separar en dos momentos el trabajo con datos, y dos archivos de código correspondientes:\n\nPreparación: corresponde a lo que se conoce generalmente como “limpieza”, es decir, realizar las modificaciones necesarias a los datos para poder efectuar los análisis. Estas modificaciones previas al análisis son necesarias ya que los datos originales con los que se va a trabajar en general no vienen perfectamente adaptados a los análisis que se quieren hacer. Por lo tanto, en cuanto a datos también hacemos la distinción entre datos originales y datos preparados (o procesados).\nAnálisis: se relaciona con análisis estadísticos, en este caso descriptivos, asociados a las preguntas e hipótesis de investigación.\n\nLos procesos de preparación y análisis vinculados tanto a datos y resultados se presentan en el siguiente esquema:\n\nTanto la preparación como el análisis (que son parte del concepto más general de procesamiento) quedan registrados cada uno en un archivo de código respectivo.\nEn esta guía nos centraremos en el análisis de datos con R. El documento de código de análisis tiene, por lo menos, 4 partes más una sección de identificación inicial:\n\nIdentificación y descripción general: Título, autor(es), fecha, información breve sobre el contenido del documento\nLibrerías: instalar/cargar librerías a utilizar\nDatos: carga de datos\nExplorar: explorar datos\nAnálisis: analizar datos y realizar estimaciones"
  },
  {
    "objectID": "content/04-content.html#cargar-librerías",
    "href": "content/04-content.html#cargar-librerías",
    "title": "Práctica 4. Análisis descriptivo de datos en R",
    "section": "1 Cargar librerías",
    "text": "1 Cargar librerías\nEste paso ya lo realizamos y cargamos todas las librerías necesarias. Pero si, al trabajar los distintos script lo hacemos en sesiones diferentes, debemos volver a cargar las librerías.\n\ninstall.packages(\"pacman\") #para instalar\nlibrary(pacman) # para llamar/cargar\n\nEn este práctico utilizaremos los siguientes paquetes:\n\npacman: este facilita y agiliza la lectura de los paquetes a utilizar en R\ntidyverse: colección de paquetes, de la cual utilizaremos dplyr y haven\ndplyr: nos permite seleccionar variables de un set de datos\npsych: para analizar descriptivamente datos\nsjmisc: para analizar descriptivamente datos\ncrosstable: para tablas cruzadas o de contingencia\n\n\npacman::p_load(tidyverse, # colección de paquetes para manipulación de datos\n               dplyr, # para manipular datos\n               psych, # para analizar datos\n               sjmisc, # para analizar datos\n               crosstable) # para tablas de contingencia\n\n\noptions(scipen = 999) # para desactivar notacion cientifica\nrm(list = ls()) # para limpiar el entorno de trabajo"
  },
  {
    "objectID": "content/04-content.html#importar-datos",
    "href": "content/04-content.html#importar-datos",
    "title": "Práctica 4. Análisis descriptivo de datos en R",
    "section": "2 Importar datos",
    "text": "2 Importar datos\nUsamos los datos creados en el procesamiento que se encuentran guardados en la carpeta output.\n\ndatos_proc <- readRDS(\"output/datos_proc.Rdata\")"
  },
  {
    "objectID": "content/04-content.html#explorar-datos",
    "href": "content/04-content.html#explorar-datos",
    "title": "Práctica 4. Análisis descriptivo de datos en R",
    "section": "3 Explorar datos",
    "text": "3 Explorar datos\n\nView(datos_proc) # Ver datos\nnames(datos_proc) # Nombre de columnas\ndim(datos_proc) # Dimensiones\nstr(datos_proc) # Estructura de los datos (las clases y categorias de repuesta)\n\nEn este caso, nuestra base de datos procesada tiene 496 casos y 9 variables."
  },
  {
    "objectID": "content/04-content.html#análisis",
    "href": "content/04-content.html#análisis",
    "title": "Práctica 4. Análisis descriptivo de datos en R",
    "section": "4 Análisis",
    "text": "4 Análisis\n\n4.1 Estadísticos descriptivos para variables categóricas\nCuando tenemos variables catégoricas, sean nominales u ordinales, podemos utilizar tablas de frecuencias. Recordemos que las frecuencias es una manera ordenar datos según el valor alcanzado en la distribución de una variable.\n\n4.1.1 Frecuencias\n\na) Absolutas y relativas\nPara las variables nominales podemos usar tablas de frecuencias absolutas y relativas, y con ellas conocer la moda, es dedir, el valor con mayor cantidad de observaciones. Para ello, una manera sencilla de hacerlo es mediante la función table de R.\n\ntable(datos_proc$sexo)\n\n\n Femenino Masculino \n      277       219 \n\ntable(datos_proc$ingreso_minimo)\n\n\ndebajo minimo  sobre minimo \n          211           285 \n\ntable(datos_proc$autor_democ)\n\n\n          A la gente como uno, nos da lo mismo un regimen democratico que uno autoritario \n                                                                                      112 \nEn algunas circunstancias, un gobierno autoritario puede ser preferible a uno democratico \n                                                                                       62 \n                           La democracia es preferible a cualquier otra forma de gobierno \n                                                                                      287 \n                                                                                  Ninguna \n                                                                                       35 \n\n\nLo anterior nos entrega la frecuencia absoluta de las variables. Con ello, podemos observar que, en cuanto la preferencias entre autoritarismo y democracia, la mayoría de nuestros casos se concentran en “La democracia es preferible a cualquier otra forma de gobierno”. Para conocer la frecuencia relativa o porcentual de estas podemos utilizar el comando prop.table.\n\n(freq_table1 <-table(datos_proc$autor_democ))\n\n\n          A la gente como uno, nos da lo mismo un regimen democratico que uno autoritario \n                                                                                      112 \nEn algunas circunstancias, un gobierno autoritario puede ser preferible a uno democratico \n                                                                                       62 \n                           La democracia es preferible a cualquier otra forma de gobierno \n                                                                                      287 \n                                                                                  Ninguna \n                                                                                       35 \n\nprop.table(freq_table1)*100 \n\n\n          A la gente como uno, nos da lo mismo un regimen democratico que uno autoritario \n                                                                                22.580645 \nEn algunas circunstancias, un gobierno autoritario puede ser preferible a uno democratico \n                                                                                12.500000 \n                           La democracia es preferible a cualquier otra forma de gobierno \n                                                                                57.862903 \n                                                                                  Ninguna \n                                                                                 7.056452 \n\n\nAsí, podemos sostener que un 57,9% de los casos concideran que la democracia es preferible a cualquier otra forma de gobierno.\n\n\nb) Acumuladas\nMientras que si trabajamos con variables ordinales, podemos usar también la frecuencia acumulada:\n\n(freq_table2 <- table(datos_proc$tramo_ingreso))\n\n\nTramo 1 Tramo 2 Tramo 3 Tramo 4 Tramo 5 \n     77     198      80      60      81 \n\n(freq_table3 <- prop.table(freq_table2)*100)\n\n\n Tramo 1  Tramo 2  Tramo 3  Tramo 4  Tramo 5 \n15.52419 39.91935 16.12903 12.09677 16.33065 \n\ncumsum(freq_table3)\n\n  Tramo 1   Tramo 2   Tramo 3   Tramo 4   Tramo 5 \n 15.52419  55.44355  71.57258  83.66935 100.00000 \n\n\nA partir de este estadístico, podemos ver que un 55% de los casos se ubican debajo del tramo 2 de ingresos, lo cual en términos sustantivos señala que un 55% de las observaciones obtienen menos de $500.000 de ingresos mensuales.\nTambién podemos unir todas estas frecuencias en una sola tabla:\n\ntbl3 <- table(datos_proc$tramo_ingreso)\ncbind(Freq=tbl3, relat = prop.table(tbl3)*100, Cum = cumsum(tbl3))\n\n        Freq    relat Cum\nTramo 1   77 15.52419  77\nTramo 2  198 39.91935 275\nTramo 3   80 16.12903 355\nTramo 4   60 12.09677 415\nTramo 5   81 16.33065 496\n\n\nOtra manera de calcular frecuencias (absolutas, relativas y acumuladas) en R, es mediante la función frq() del paquete sjmisc, el cual entrega todo lo anterior con un solo comando.\n\nsjmisc::frq(datos_proc$tramo_ingreso)\n\nx <character> \n# total N=496 valid N=496 mean=2.74 sd=1.31\n\nValue   |   N | Raw % | Valid % | Cum. %\n----------------------------------------\nTramo 1 |  77 | 15.52 |   15.52 |  15.52\nTramo 2 | 198 | 39.92 |   39.92 |  55.44\nTramo 3 |  80 | 16.13 |   16.13 |  71.57\nTramo 4 |  60 | 12.10 |   12.10 |  83.67\nTramo 5 |  81 | 16.33 |   16.33 | 100.00\n<NA>    |   0 |  0.00 |    <NA> |   <NA>\n\n\n\n\n\n4.1.2 Tablas de contingencia\nTambién podemos cruzar dos variables mediante las llamadas tablas de contingencia o tablas cruzadas. Además de conocer la frecuencia absoluta en cada casilla, podemos también conocer la proporción o frecuencia relativa para cada casilla y el total de la filas y columnas.\n\ncrosstable(datos_proc, cols = sexo, by = tramo_edad)\n\n# A tibble: 2 × 6\n  .id   label variable  Adultos      `Adutos mayores` Jovenes   \n  <chr> <chr> <chr>     <chr>        <chr>            <chr>     \n1 sexo  sexo  Femenino  210 (75.81%) 44 (15.88%)      23 (8.30%)\n2 sexo  sexo  Masculino 152 (69.41%) 49 (22.37%)      18 (8.22%)\n\ncrosstable(datos_proc, cols = sexo, by = tramo_edad, total = \"both\") #fila y columna\n\n# A tibble: 3 × 7\n  .id   label variable  Adultos      `Adutos mayores` Jovenes    Total        \n  <chr> <chr> <chr>     <chr>        <chr>            <chr>      <chr>        \n1 sexo  sexo  Femenino  210 (75.81%) 44 (15.88%)      23 (8.30%) 277 (55.85%) \n2 sexo  sexo  Masculino 152 (69.41%) 49 (22.37%)      18 (8.22%) 219 (44.15%) \n3 sexo  sexo  Total     362 (72.98%) 93 (18.75%)      41 (8.27%) 496 (100.00%)\n\ncrosstable(datos_proc, cols = sexo, by = tramo_edad, total = \"row\") #solo fila\n\n# A tibble: 2 × 7\n  .id   label variable  Adultos      `Adutos mayores` Jovenes    Total       \n  <chr> <chr> <chr>     <chr>        <chr>            <chr>      <chr>       \n1 sexo  sexo  Femenino  210 (75.81%) 44 (15.88%)      23 (8.30%) 277 (55.85%)\n2 sexo  sexo  Masculino 152 (69.41%) 49 (22.37%)      18 (8.22%) 219 (44.15%)\n\ncrosstable(datos_proc, cols = sexo, by = tramo_edad, total = \"column\") #solo columna\n\n# A tibble: 3 × 6\n  .id   label variable  Adultos      `Adutos mayores` Jovenes   \n  <chr> <chr> <chr>     <chr>        <chr>            <chr>     \n1 sexo  sexo  Femenino  210 (75.81%) 44 (15.88%)      23 (8.30%)\n2 sexo  sexo  Masculino 152 (69.41%) 49 (22.37%)      18 (8.22%)\n3 sexo  sexo  Total     362 (72.98%) 93 (18.75%)      41 (8.27%)\n\n\n\n\n\n4.2 Estadísticos descriptivos para variables númericas\nA diferencia de las variables categóricas, a las variables numéricas (intervalaras o de razón) les podemos calcular una mayor cantidad de estadísticos descriptivos, como medidas de tendencia central, dispersión o posición.\nComo ya vimos en clases:\n\ndentro de las medidas de tendencia central que podemos calcular para describir a una variable numérica encontramos: media, mediana;\ndentro de las medidas de dispersión podemos señalar: desviación estándar, variancia, coeficiente de variación, rango;\ndentro de las medidas de posición podemos mencionar: mediana, q1, q3, mínimo, máximo.\n\n\n\n\n\n\n\nTip\n\n\n\nRecordemos que:\n\nlas medidads de tendencia central expresan el valor alrededor del cual se sitúa la mayor cantidad de los datos. Estamos mirando hacia el centro de los datos.\nlas medidas de dispersión buscan cuantificar lo próximo o alejado que están los valores de una variable de un punto central. Estamos mirando la dispersión de los datos respecto a su centro.\nlas medidas de posición señalan en qué “lugar” de una distribución se encuentra un dato o un conjunto de datos en relación al resto.\n\n\n\nEn R existen distintas formas de cálcular este tipo de estadísticos descriptivos.\n\na) Con summary\nPodemos obtener rapidamente un resumen de los datos con la funcion summary de R\n\nsummary(datos_proc$ingreso)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n      0  350000  500000  679514  800000 5000000 \n\n\nCon esto podemos ver que el promedio o media aritmética del ingreso individual de los entrevistados de nuestra base es de $679.514, mientras que la mediana es de 500.000 pesos.\nAsimismo, observamos que el 25% de la parte inferior de nuestros datos obtiene igual o menos de $350.000, en tanto que el 25% superior de la distribución de los datos gana igual o más de 800.000 pesos.\nSin embargo, aunque es informativo, no nos entrega toda la información que quisieramos.\n\n\nb) Con psych\n\npsych::describe(datos_proc$ingreso,\n                quant = c(.25,.75),\n                IQR = T)\n\n  vars   n     mean       sd median  trimmed    mad min     max   range skew\n1    1 496 679514.1 611376.9 500000 572434.7 296520   0 5000000 5000000 3.01\n  kurtosis       se    IQR  Q0.25  Q0.75\n1    13.42 27451.63 450000 350000 800000\n\n\nUsando la funcion describe del paquete psych podemos obtener mayor cantidad de estadísticos, además de especificarle otros adicionales.\nAsí, por ejemplo, ahora además de la media aritmética y la media, también tenemos la media recortada.\nPero lo más relevante es que nos aporta estadísticos de la dispersión de los datos, como la desviación estandár que nos indica que el grado de dispersión de mis datos respecto al promedio de ingresos es de $611.376. Con esto, podemos obtener también la varianza de los datos, que corresponde a la DS al cuadrado.\nAdemás de eso, nos aporta el rango (el valor máximo menos el mínimo), y el recorrido interquartilico (Q3 - Q1) que nos indica el grado de dispersión del 50% de los datos.\nCon esta información, podemos calcular los demás estadísticos que necesitamos “a mano”, es decir, computandolos directamente en R como una cálculadora.\n\n\nc) Con summarise de dplyr\nOtra manera de obtener todos los estadísticos que necesitamos es utilizando dplyr. Aquí, le especificamos lo que requerimos, pero debemos saber bien cómo calcular tales medidas:\n\ndatos_proc %>% \n  summarise(media = mean(ingreso),\n            mediana = median(ingreso),\n            q1 = quantile(ingreso, probs = .25),\n            q2 = quantile(ingreso, probs = .75),\n            rango = max(ingreso) - min(ingreso),\n            desviacion_estandar = sd(ingreso),\n            varianza = var(ingreso),\n            coef_variacion = sd(ingreso)/mean(ingreso))\n\n# A tibble: 1 × 8\n    media mediana     q1     q2   rango desviacion_estandar     varianza coef_…¹\n    <dbl>   <dbl>  <dbl>  <dbl>   <dbl>               <dbl>        <dbl>   <dbl>\n1 679514.  500000 350000 800000 5000000             611377.      3.74e11   0.900\n# … with abbreviated variable name ¹​coef_variacion\n\n\nAhora, conocemos no solo los estádisticos anteriores, sino que también obtuvimos la varianza y el coeficiente de variación."
  },
  {
    "objectID": "content/04-content.html#resumen",
    "href": "content/04-content.html#resumen",
    "title": "Práctica 4. Análisis descriptivo de datos en R",
    "section": "Resumen",
    "text": "Resumen\nHoy aprendimos a procesar datos en R. En detalle, vimos:\n\nCómo establecer un flujo de trabajo de procesamiento y análisis de datos en R.\nRealizar análisis descriptivos en R según el nivel de medición de las variables"
  },
  {
    "objectID": "content/04-content.html#video-de-clase",
    "href": "content/04-content.html#video-de-clase",
    "title": "Práctica 4. Análisis descriptivo de datos en R",
    "section": "Video de clase",
    "text": "Video de clase"
  },
  {
    "objectID": "content/05-content.html",
    "href": "content/05-content.html",
    "title": "Práctica 5. Repaso procesamiento y análisis de datos en R",
    "section": "",
    "text": "El objetivo de esta guía práctica es repasar los procedimientos básicos para el procesamiento y análisis descripivo de datos en R, los cuales fueron vistos en las sesiones pasadas del laboratorio.\nEn detalle, aprenderemos:\n\nEstablecer un flujo de trabajo en R.\nProcesar, limpiar y transformar bases de datos en R.\nRealizar análisis desciptivos (medidas de posición, tendencia central y dispersión) en R.\n\n¡Al final de esta práctica la idea es que cada un_ elabore y entienda su propio documento de preparación y análisis de datos!\n\n\n\nEn esta práctica trabajaremos con un subset de los datos del Estudio Longitudinal Social de Chile (ELSOC) realizado por COES. Esta base la pueden encontrar en el canal de U-Cursos sección Material Docente, o bien, en el siguiente enlace  ELSOC 2022 podrán descargar el archivo que contiene la base ELSOC 2022.\nRecuerden que siempre es importante trabajar con el manual/libro de códigos de las bases de datos. El manual de la ELSOC 2022 lo pueden encontrar aquí."
  },
  {
    "objectID": "content/05-content.html#video-de-clase",
    "href": "content/05-content.html#video-de-clase",
    "title": "Práctica 5. Repaso procesamiento y análisis de datos en R",
    "section": "Video de clase",
    "text": "Video de clase\n\nPrimer bloque\n\n\n\nSegundo bloque"
  },
  {
    "objectID": "content/06-content.html",
    "href": "content/06-content.html",
    "title": "Práctica 6. Visualización de datos con R",
    "section": "",
    "text": "El objetivo de esta guía práctica es introducir a la visualización de datos con R, considerando las mejores prácticas para comunicar datos y análisis en ciencias sociales.\nEn detalle, aprenderemos:\n\nQué es la visualización de datos y cómo comunicarlos a una audiencia de manera eficiente, completa e insesgada.\nVisualizar datos univariados con {ggplot2}.\n\n\n\n\nEn esta práctica trabajaremos con la base de datos de la Encuesta de Opinión Pública (CEP) de Diciembre del 2019 realizada por el Centro de Estudios Públicos. Esta base la pueden encontrar en el canal de U-Cursos sección Material Docente, o bien, en el siguiente enlace  CEP 2019 podrán descargar el archivo que contiene la base CEP Diciembre 2019."
  },
  {
    "objectID": "content/06-content.html#cargar-librerías",
    "href": "content/06-content.html#cargar-librerías",
    "title": "Práctica 6. Visualización de datos con R",
    "section": "1. Cargar librerías",
    "text": "1. Cargar librerías\nPara esta sesión, usaremos librerías que ya conocemos en prácticos pasados:\n\npacman::p_load(tidyverse, # colección de paquetes para manipulación de datos\n               haven, # para importar datos\n               car,# para recodificar datos\n               psych, # para analizar datos\n               sjmisc) # para analizar datos\n\noptions(scipen = 999) # para desactivar notacion cientifica\nrm(list = ls()) # para limpiar el entorno de trabajo"
  },
  {
    "objectID": "content/06-content.html#importar-datos",
    "href": "content/06-content.html#importar-datos",
    "title": "Práctica 6. Visualización de datos con R",
    "section": "2. Importar datos",
    "text": "2. Importar datos\nCargamos la base de datos CEP Diciembre 2019 mediante el paquete haven\n\ncep <- haven::read_sav(\"Input/data/CEP_dic2019.sav\")"
  },
  {
    "objectID": "content/06-content.html#limpiar-datos",
    "href": "content/06-content.html#limpiar-datos",
    "title": "Práctica 6. Visualización de datos con R",
    "section": "3. Limpiar datos",
    "text": "3. Limpiar datos\nSeleccionamos las variables de interés y las renombramos:\n\nproc_cep <- cep %>% \n  select(edad = DS_P2_EXACTA,\n         sexo = DS_P1,\n         empleo = DS_P5, \n         satisfaccion = SV_1)\n\nRecodificamos las variables satisfaccion, sexo y empleo. Ademas, transformamos la variable edad a tramos:\n\nproc_cep$sexo <- as.factor(proc_cep$sexo) # primero pasamos a factor la variable al venir con etiquetas\nproc_cep$empleo <- as.factor(proc_cep$empleo)\n\nproc_cep <- proc_cep %>% \n  mutate(satisfaccion=car::recode(satisfaccion, recodes = c(\"88 = NA; 99 = NA\")),\n         sexo = car::recode(sexo, recodes = c(\"1 = 'Hombre'; 2 = 'Mujer'\")),\n         empleo = car::recode(empleo, recodes = c(\"1 = 'Ocupado'; 2 = 'Desocupado'; 3 = 'Nunca ha trabajado'; 99 = NA\")),\n         tramo_edad = case_when(edad <= 29 ~ \"Jovenes\",\n                                edad >= 30 & edad <= 59 ~ \"Adultos\",\n                                edad >= 60 ~ \"Adutos mayores\")) \n\nRemovemos los valores perdidos o missing.\n\nproc_cep <- na.omit(proc_cep)\n\nPor último, guardamos la base procesada.\n\nsaveRDS(proc_cep, file = \"Output/proc_cep.RData\")"
  },
  {
    "objectID": "content/06-content.html#resumen",
    "href": "content/06-content.html#resumen",
    "title": "Práctica 6. Visualización de datos con R",
    "section": "Resumen",
    "text": "Resumen\nHoy aprendimos a visualizar datos en R. En detalle, vimos:\n\nQué es la visualización de datos y cómo comunicarlos a una audiencia de manera eficiente, completa e insesgada.\nVisualizar datos univariados de diversas formas con {ggplot2}."
  },
  {
    "objectID": "content/06-content.html#video-tutorial",
    "href": "content/06-content.html#video-tutorial",
    "title": "Práctica 6. Visualización de datos con R",
    "section": "Video tutorial",
    "text": "Video tutorial"
  },
  {
    "objectID": "content/07-content.html",
    "href": "content/07-content.html",
    "title": "Práctica 7. Forma de una distribución",
    "section": "",
    "text": "El objetivo de esta guía práctica es aplicar los conocimientos aprendidos en clases sobre la forma de una distribución en R, comprendiendo sus usos, relevancia y formas de analizarla.\nEn detalle, aprenderemos:\n\nLa noción de una distribución y sus tipos (continuas y discretas)\nEstimar e interpretar la asimetría y curtosis de una distribución\nContrastar distribuciones empíricas con teóricas\n\n\n\n\nEn esta práctica trabajeremos con los datos procesados que obtuvimos en la práctica anterior, en la cual trabajamos sobre la Encuesta de Opinión Pública (CEP) de Diciembre del 2019 realizada por el Centro de Estudios Públicos."
  },
  {
    "objectID": "content/07-content.html#distribuciones-continuas-y-discretas",
    "href": "content/07-content.html#distribuciones-continuas-y-discretas",
    "title": "Práctica 7. Forma de una distribución",
    "section": "1. Distribuciones continuas y discretas",
    "text": "1. Distribuciones continuas y discretas\nExisten dos tipos de distribuciones según el nivel de medición de las variables: las continuas y las discretas.\nComo cabe esperar, las distribuciones continuas aplican a variables numericas (intervalares y de razón). Es una distribución que describe la probabilidad o frecuencia de que una variable continua tome un valor particular dado un intervalo o un rango. Toma valores a lo largo de un continuo de dominio (\\(R\\)), es decir, su dominio son todos los números reales.\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nPor su parte, las distribuciones discretas son comunmente utilizadas con variables categóricas (nominales y ordinales). Son distribuciones en las que una variable sólo puede tomar un número contable de valores distintos. En otras palabras, es una distribución en la que la variable sólo puede tomar valores específicos, en lugar de cualquier valor dentro de un intervalo. Su dominio es un conjunto de valores enteros (\\(N, Z, Q\\))."
  },
  {
    "objectID": "content/07-content.html#preparación-de-datos",
    "href": "content/07-content.html#preparación-de-datos",
    "title": "Práctica 7. Forma de una distribución",
    "section": "1. Preparación de datos",
    "text": "1. Preparación de datos\nCargamos las librerías y datos que ocuparemos\n\npacman::p_load(tidyverse, \n               psych, \n               sjmisc) \n\noptions(scipen = 999) \nrm(list = ls()) \n\nproc_cep <- readRDS(\"Output/proc_cep.RData\")"
  },
  {
    "objectID": "content/07-content.html#análisis-de-la-forma-de-distribución",
    "href": "content/07-content.html#análisis-de-la-forma-de-distribución",
    "title": "Práctica 7. Forma de una distribución",
    "section": "2. Análisis de la forma de distribución",
    "text": "2. Análisis de la forma de distribución\nAnalicemos e interpretemos la forma de la distribución de nuestras variables. En este ejemplo tenemos:\n\nuna de razón,\nuna ordinal de 10 categorías.\n\n\npsych::describe(proc_cep$edad)\n\n   vars    n  mean    sd median trimmed  mad min max range skew kurtosis   se\nX1    1 1474 48.43 17.84   48.5   48.01 21.5  18  99    81 0.14    -0.93 0.46\n\nggplot(data = proc_cep, \n       mapping = aes(x = edad)) + \n  geom_density(color = \"black\", fill = \"#FA8072\", alpha = 0.8)  + \n  labs(title =\"Diagrama densidad: Edad\", \n       x = \"Edad\", \n       y = \"Frecuencia\",\n       caption = \"Fuente: Elaboración propia en base a Encuesta CEP Diciembre 2019.\") \n\n\n\n\nA partir de los estadísticos entregados, sabemos que la variable edad tiene una asimetría positiva (skew = 0.14) pero baja (< 0.5), lo cual indica que los datos se tienden a distribuir hacía los menores valores del eje X. Por su parte, la curtosis es negativa (kurtosis = -0.93) o platicúrtica, lo cual indica que existe una baja concentración en el centro de los datos.\n\npsych::describe(proc_cep$satisfaccion)\n\n   vars    n mean   sd median trimmed  mad min max range  skew kurtosis   se\nX1    1 1474 6.87 2.18      7    6.97 2.97   1  10     9 -0.32    -0.45 0.06\n\nggplot(data = proc_cep, \n       mapping = aes(x = satisfaccion)) + \n  geom_density(color = \"black\", fill = \"darkred\", alpha = 0.8)  + \n  labs(title =\"Histograma densidad: Satisfaccion\", \n       x = \"Satisfaccion\", \n       y = \"Frecuencia\",\n       caption = \"Fuente: Elaboración propia en base a Encuesta CEP Diciembre 2019.\") \n\n\n\n\nEn cuanto a la variable satisfaccion, tenemos una asimetría negativa (skew = -0.32) aunque baja, indicando que los datos se tienden a distribuir hacia la parte superior de la variable. Además, la curtosis también es negativa o platicúrtica (kurtosis = -0.45), por lo que existe una baja concentración en el centro de los datos."
  },
  {
    "objectID": "content/07-content.html#resumen",
    "href": "content/07-content.html#resumen",
    "title": "Práctica 7. Forma de una distribución",
    "section": "Resumen",
    "text": "Resumen\nHoy aprendimos a visualizar datos en R. En detalle, vimos:\n\nLa noción de una distribución y sus tipos (continuas y discretas)\nEstimar e interpretar la asimetría y curtosis de una distribución\nContrastar distribuciones empíricas con teóricas"
  },
  {
    "objectID": "content/07-content.html#video-tutorial",
    "href": "content/07-content.html#video-tutorial",
    "title": "Práctica 7. Forma de una distribución",
    "section": "Video tutorial",
    "text": "Video tutorial"
  },
  {
    "objectID": "content/08-content.html",
    "href": "content/08-content.html",
    "title": "Inferencia estadística univariada",
    "section": "",
    "text": "El objetivo de esta guía práctica es aplicar los conocimientos aprendidos en clases sobre inferencia estadística univariada, comprendiendo sus fundamentos, relevancia y aplicación a un caso concreto en R.\nEn detalle, aprenderemos:\n\nEstablecer el diseño muestral de una base de datos en R.\nRealizar estimaciones puntuales e intervalares para medias y proporciones.\nContrastar hipótesis univariadas.\n\n\n\n\nEn esta práctica trabajaremos con la base de datos de la Encuesta Suplementaria de Ingresos (ESI) del 2021 realizada por el Instituto Nacional de Estadísticas (INE). Esta base la pueden encontrar en el canal de U-Cursos sección Material Docente, o bien, en el siguiente enlace  ESI 2021 podrán descargar el archivo que contiene la base ESI 2021."
  },
  {
    "objectID": "content/08-content.html#cargar-librerías",
    "href": "content/08-content.html#cargar-librerías",
    "title": "Inferencia estadística univariada",
    "section": "1. Cargar librerías",
    "text": "1. Cargar librerías\nPara esta sesión, usaremos librerías que ya conocemos en prácticos pasados y una nueva, llamada srvyr:\n\npacman::p_load(tidyverse, # colección de paquetes para manipulación de datos\n               car, # para recodificar\n               psych, # para analizar datos\n               sjmisc,  # para analizar datos\n               srvyr) # para estimación de IC y ponderadores\n\noptions(scipen = 999) # para desactivar notacion cientifica\nrm(list = ls()) # para limpiar el entorno de trabajo"
  },
  {
    "objectID": "content/08-content.html#importar-datos",
    "href": "content/08-content.html#importar-datos",
    "title": "Inferencia estadística univariada",
    "section": "2. Importar datos",
    "text": "2. Importar datos\nCargamos la base de datos ESI 2021 con readRDS\n\nesi <- readRDS(\"Input/data/esi-2021-ocupados.RData\")"
  },
  {
    "objectID": "content/08-content.html#recodificar",
    "href": "content/08-content.html#recodificar",
    "title": "Inferencia estadística univariada",
    "section": "3. Recodificar",
    "text": "3. Recodificar\nSolo recodificamos y convertiremos a factor la variable sexo.\n\nesi$sexo <- car::recode(esi$sexo, recodes = c(\" 1 = 'Hombre'; 2 = 'Mujer'\"), as.factor = T)"
  },
  {
    "objectID": "content/08-content.html#resumen",
    "href": "content/08-content.html#resumen",
    "title": "Inferencia estadística univariada",
    "section": "Resumen",
    "text": "Resumen\nHoy aprendimos a realizar inferencia estádistica en R. En detalle, vimos:\n\nEstablecer el diseño muestral de una base de datos en R.\nRealizar estimaciones puntuales e intervalares para medias y proporciones.\nContrastar hipótesis univariadas."
  },
  {
    "objectID": "content/08-content.html#video-de-la-sesión",
    "href": "content/08-content.html#video-de-la-sesión",
    "title": "Inferencia estadística univariada",
    "section": "Video de la sesión",
    "text": "Video de la sesión"
  },
  {
    "objectID": "content/index.html",
    "href": "content/index.html",
    "title": "Laboratorio de Análisis de Datos",
    "section": "",
    "text": "En esta sección se encuentran las guías prácticas a desarrollar durante las sesiones del Laboratorio de Análisis de Datos.\nTodo el material es accesible desde el menú de la izquierda <–"
  },
  {
    "objectID": "content/index.html#instrucciones-generales-para-las-prácticas",
    "href": "content/index.html#instrucciones-generales-para-las-prácticas",
    "title": "Laboratorio de Análisis de Datos",
    "section": "Instrucciones generales para las prácticas",
    "text": "Instrucciones generales para las prácticas\n\nLas instancia prácticas consisten en el desarrollo de una guía práctica cada 2 semanas donde se aplican y profundizan los contenidos de las clases mediante las herramientas del lenguaje R. La organización de estas prácticas se puede revisar en la planificación del curso.\nEstas sesiones acompañarán el desarrollo de las guías prácticas disponibles en este sitio.\nEn las prácticas vamos a trabajar con el software R, Versión 4.2.2\nPara poder tener una asesoría y monitoreo más cercano en el desarrollo de las guías, los estudiantes han sido divididos en grupos asignados a un/a ayudante (ver en UCursos).\nEl trabajo con estas guías se organiza en los siguientes momentos:\n\nlas sesiones de laboratorios serán en modalidad online, en donde el equipo docente guiará el desarrollo del práctico\nel equipo docente mostrará el código para cada sesión, el cual contendrá los mismos contenidos de las guías alojadas en este sitio\nen paralelo, cada estudiante realiza esta guía de manera autónoma durante la sesión de laboratorio en su propio computador, apoyándose en el código que mostrarán los apoyos docentes\nen caso de dudas, las realizan en los foros disponibles o se contactan directamente con su ayudante"
  },
  {
    "objectID": "content/index.html#trabajo-con-software-r",
    "href": "content/index.html#trabajo-con-software-r",
    "title": "Laboratorio de Análisis de Datos",
    "section": "Trabajo con software R",
    "text": "Trabajo con software R\nPara los análisis estadísticos de este curso usamos el programa R, en parte porque es gratuito, pero la principal razón es que es de código abierto. Esto quiere decir que cualquier persona puede revisar cómo está hecho y aportar con modificaciones y procedimientos nuevos, como son las librerías que realizan funciones específicas.\nEl carácter de apertura de R posee muchas ventajas, pero también conlleva complicaciones. Se actualiza permanentemente, así como también las librerías, y esto puede generar problemas de compatibilidad y de fallas en ejecución del código de análisis.\nPara minimizar estos posibles problemas en este curso, vamos a:\n\ntrabajar con la misma y última versión de R, que es la 4.2\nevitar uso de tilde, ñ, espacios y mayúsculas tanto en carpetas y archivos, así como también en los nombres de las variables\nal momento de hacer consultas sobre problemas en la ejecución del código, adjuntar la siguiente información:\n\nCódigo completo hasta que se produce el problema\nIndicar línea del código donde se produce el problema\nAdjuntar el resultado del output de la información de la sesión (sessionInfo())\n\n\n\nInstalación de R & RStudio\nPara esta versión del curso vamos a trabajar con el programa R Version 4.2 (se sugiere la última versión 4.2.2) y con RStudio, que ofrece un entorno más amigable para trabajar con R.\nPara instalar R: ir a https://cran.r-project.org/index.html y bajar/instalar la versión correspondiente a la plataforma utilizada (Windows, Mac o Linux)\nPara instalar RStudio: ir a https://posit.co/downloads/ y bajar/instalar RStudio desktop, Open Source License (libre).\nSi por alguna razón se prefiere trabajar sin descargar, también se puede utilizar RCloud, abajo un tutorial de una versión anterior del curso de estadística multivarada\n\n\n\n\n\n\n\nSobre el trabajo en hojas de código en RStudio\n\nEl trabajo de análisis en RStudio se efectua en una hoja de código (o R script o sintaxis, o para los usuarios de Stata la do-file), que es donde se anotan los comandos y funciones. Para abrir una hoja, en RStudio ir a File > New File > R Script (o ctrl+shift+N),y aparecerá un panel con una pestaña “Untitled” (sin título). Esta es la hoja de código donde se anotan los comandos.\nLos contenidos de las hojas de código son básicamente 2:\n\ncomandos o funciones: se escriben en la hoja, y para ejecutarlos se debe posicionar el cursor en la línea respectiva y ctrl+enter, el resultado aparecerá en el panel de resultados o Consola.\ntexto: para escribir títulos, comentarios, y todo lo que permita entender qué se está haciendo, al principio de la línea respectiva escribir el signo #\n\nPara grabar nuestra hoja de código y así respaldar nuestros análisis, File > Save (o ctrl+s), y dar un nombre al archivo. Recordar: breve, sin espacios ni tildes ni eñes. Por defecto, la extensión de estos archivos es .R"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Estadística Descriptiva",
    "section": "",
    "text": "Estadística Descriptiva\n        \n        \n            \n        \n        \n            SOC01014-1 • Primer Semestre 2023Departamento de Sociología FACSOUniversidad de Chile\n        \n    \n    \n        \n    \n\n\n\n\n\nProfesor\n\n   Rodrigo Asún\n   Departamento de Sociología FACSO\n   rasun@uchile.cl\n\n\n\nEquipo docente\n\n   Daniela Olivares\n   danielaolivarescollio@gmail.com\n   Andreas Laffert\n   andreas.laffert@ug.uchile.cl\n\n\n\nInformación del curso\n\n   Jueves\n   Marzo–Julio, 2023\n   8:30 AM - 11:45 AM\n   Aulario A - sala 7 y 8\n   Prácticos Vía Zoom\n\n\n\nContacto\nA través de correo o U-Cursos"
  },
  {
    "objectID": "resource/01-resource.html",
    "href": "resource/01-resource.html",
    "title": "Bases de datos",
    "section": "",
    "text": "Encuestas CEP\nELSOC\nCASEN\nENETS\nENE\nESI\nENCLA\nENUT\nEstudios PNUD\nENDIDE\nEANNA"
  },
  {
    "objectID": "resource/01-resource.html#internacionales",
    "href": "resource/01-resource.html#internacionales",
    "title": "Bases de datos",
    "section": "Internacionales",
    "text": "Internacionales\n\nILO\nWID\nSWIID\nICTWSS\nOECD\nBanco Mundial"
  },
  {
    "objectID": "resource/01-resource.html#comparativas",
    "href": "resource/01-resource.html#comparativas",
    "title": "Bases de datos",
    "section": "Comparativas",
    "text": "Comparativas\n\nWorld Values Survey\nISSP\nESS\nLAPOP\nLatinobarómetro"
  },
  {
    "objectID": "resource/02-resource.html",
    "href": "resource/02-resource.html",
    "title": "Uso de R",
    "section": "",
    "text": "Recursos web para aprender R\n\nR para Ciencia de Datos\nHands-On Programming with R\nManual de R\nMás libros de R\nAnalizaR Datos Políticos\nR Cheatsheets\nGuías rápidas en R\nRStudio para Estadística Descriptiva en Ciencias Sociales\n\n\n\nVisualización de datos en R\n\nR Graph Gallery\nData to Viz\nData Visualization Course\n\n\n\nSitios de consulta y comunidad de R\n\nStack Overflow\nGeeks for geeks\nChatGPT\nRstudio Community"
  },
  {
    "objectID": "resource/03-resource.html",
    "href": "resource/03-resource.html",
    "title": "Importar datos en R",
    "section": "",
    "text": "pacman::p_load(tidyverse,\n               sjmisc,\n               dplyr,\n               haven, # para .dta, .sav\n               readr, # para .csv\n               readxl) # para archivos excel \n\n\n\n\n\n\nLos archivos con extensión .dta generalmente provienen de Stata, es decir, son bases o datos procesadas en dicho software. Para estos archivos, así como aquellos que vienen en .sav, usamos el paquete haven(). En estos casos siempre es conveniente señalar el tipo de encoding en el argumento, en este caso, usamos \"UTF-8\" que corresponde al estandar.\n\nelsoc_2022 <- haven::read_dta(file = \"input/data/ELSOC_W06_v1.0_Stata.dta\", encoding = \"UTF-8\")\n\nelsoc_2022\n\n# A tibble: 2,730 × 437\n   idencuesta ola       version muestra   cuest…¹ cuest…² formato segme…³ comuna\n        <dbl> <dbl+lbl>   <dbl> <dbl+lbl> <dbl+l> <dbl+l> <dbl+l>   <dbl> <chr> \n 1    1101011 6 [2022]   202201 1 [Muest… 2 [Ven… 1 [Com… 1 [CAP…  110101 Iquiq…\n 2    1101012 6 [2022]   202201 1 [Muest… 2 [Ven… 1 [Com… 1 [CAP…  110101 Iquiq…\n 3    1101023 6 [2022]   202201 1 [Muest… 2 [Ven… 1 [Com… 1 [CAP…  110102 Iquiq…\n 4    1101041 6 [2022]   202201 1 [Muest… 2 [Ven… 1 [Com… 1 [CAP…  110104 Iquiq…\n 5    1101081 6 [2022]   202201 1 [Muest… 2 [Ven… 1 [Com… 1 [CAP…  110108 Iquiq…\n 6    1101082 6 [2022]   202201 1 [Muest… 1 [Per… 1 [Com… 1 [CAP…  110108 Iquiq…\n 7    1101102 6 [2022]   202201 1 [Muest… 2 [Ven… 1 [Com… 1 [CAP…  110110 San F…\n 8    1101103 6 [2022]   202201 1 [Muest… 1 [Per… 1 [Com… 1 [CAP…  110110 Iquiq…\n 9    1101111 6 [2022]   202201 1 [Muest… 2 [Ven… 1 [Com… 1 [CAP…  110111 Iquiq…\n10    1101113 6 [2022]   202201 1 [Muest… 1 [Per… 1 [Com… 1 [CAP…  110111 Iquiq…\n# … with 2,720 more rows, 428 more variables: comuna_cod <dbl+lbl>,\n#   region <chr>, region_cod <dbl+lbl>, estrato <dbl+lbl>, ponderador01 <dbl>,\n#   ponderador02 <dbl>, fact_exp01 <dbl>, fact_exp02 <dbl>, r05_01 <dbl+lbl>,\n#   r05_02 <dbl+lbl>, r06 <dbl+lbl>, r07 <dbl+lbl>, r08 <dbl+lbl>,\n#   r09 <dbl+lbl>, r10 <dbl+lbl>, r11 <dbl+lbl>, r12_01 <dbl+lbl>,\n#   r12_02 <dbl+lbl>, r12_03 <dbl+lbl>, r12_04 <dbl+lbl>, r12_05 <dbl+lbl>,\n#   r12_06 <dbl+lbl>, r12_07 <dbl+lbl>, r13_nredes <dbl>, …\n\n\n\n\n\nPara los archivos con extension .csv usamos el paquete readr::. Importante es que los archivos .csv vienen separados por comas ,.\n\nelsoc_2022 <- readr::read_csv(file =\"input/data/ELSOC_W06_v1.0_CSV.csv\")\n\nRows: 2730 Columns: 437\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (14): comuna, region, c12_09_otro, c16_otro, c17_otro, c20_otro, m36_o...\ndbl  (422): idencuesta, ola, version, muestra, cuestion_mig, cuestion_comple...\ndate   (1): fecha_entr\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nelsoc_2022\n\n# A tibble: 2,730 × 437\n   idencu…¹   ola version muestra cuest…² cuest…³ formato segme…⁴ comuna comun…⁵\n      <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>    <dbl>\n 1  1101011     6  202201       1       2       1       1  110101 Iquiq…    1101\n 2  1101012     6  202201       1       2       1       1  110101 Iquiq…    1101\n 3  1101023     6  202201       1       2       1       1  110102 Iquiq…    1101\n 4  1101041     6  202201       1       2       1       1  110104 Iquiq…    1101\n 5  1101081     6  202201       1       2       1       1  110108 Iquiq…    1101\n 6  1101082     6  202201       1       1       1       1  110108 Iquiq…    1101\n 7  1101102     6  202201       1       2       1       1  110110 San F…    6301\n 8  1101103     6  202201       1       1       1       1  110110 Iquiq…    1101\n 9  1101111     6  202201       1       2       1       1  110111 Iquiq…    1101\n10  1101113     6  202201       1       1       1       1  110111 Iquiq…    1101\n# … with 2,720 more rows, 427 more variables: region <chr>, region_cod <dbl>,\n#   estrato <dbl>, ponderador01 <dbl>, ponderador02 <dbl>, fact_exp01 <dbl>,\n#   fact_exp02 <dbl>, r05_01 <dbl>, r05_02 <dbl>, r06 <dbl>, r07 <dbl>,\n#   r08 <dbl>, r09 <dbl>, r10 <dbl>, r11 <dbl>, r12_01 <dbl>, r12_02 <dbl>,\n#   r12_03 <dbl>, r12_04 <dbl>, r12_05 <dbl>, r12_06 <dbl>, r12_07 <dbl>,\n#   r13_nredes <dbl>, r13_sexo_01 <dbl>, r13_edad_01 <dbl>,\n#   r13_relacion_01 <dbl>, r13_tiempo_01 <dbl>, r13_barrio_01 <dbl>, …\n\n\n\n\n\nPara los archivos que provienen de Excel, tales como los .xlsx usamos el paquete readxl::. Noten que podemos cargar la base completa, como en el primer ejemplo, pero también podemos especificarle que queremos determinadas columnas y filas de un archivo Excel, como en el segundo ejmplo.\n\nelsoc_2022 <- readxl::read_excel(\"input/data/ELSOC_W06_v1.0_EXCEL.xlsx\")\n\nelsoc_2022\n\n# A tibble: 2,730 × 437\n   idencu…¹   ola version muestra cuest…² cuest…³ formato segme…⁴ comuna comun…⁵\n      <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>    <dbl>\n 1  1101011     6  202201       1       2       1       1  110101 Iquiq…    1101\n 2  1101012     6  202201       1       2       1       1  110101 Iquiq…    1101\n 3  1101023     6  202201       1       2       1       1  110102 Iquiq…    1101\n 4  1101041     6  202201       1       2       1       1  110104 Iquiq…    1101\n 5  1101081     6  202201       1       2       1       1  110108 Iquiq…    1101\n 6  1101082     6  202201       1       1       1       1  110108 Iquiq…    1101\n 7  1101102     6  202201       1       2       1       1  110110 San F…    6301\n 8  1101103     6  202201       1       1       1       1  110110 Iquiq…    1101\n 9  1101111     6  202201       1       2       1       1  110111 Iquiq…    1101\n10  1101113     6  202201       1       1       1       1  110111 Iquiq…    1101\n# … with 2,720 more rows, 427 more variables: region <chr>, region_cod <dbl>,\n#   estrato <dbl>, ponderador01 <dbl>, ponderador02 <dbl>, fact_exp01 <dbl>,\n#   fact_exp02 <dbl>, r05_01 <dbl>, r05_02 <dbl>, r06 <dbl>, r07 <dbl>,\n#   r08 <dbl>, r09 <dbl>, r10 <dbl>, r11 <dbl>, r12_01 <dbl>, r12_02 <dbl>,\n#   r12_03 <dbl>, r12_04 <dbl>, r12_05 <dbl>, r12_06 <dbl>, r12_07 <dbl>,\n#   r13_nredes <dbl>, r13_sexo_01 <dbl>, r13_edad_01 <dbl>,\n#   r13_relacion_01 <dbl>, r13_tiempo_01 <dbl>, r13_barrio_01 <dbl>, …\n\n\nEn este caso le especificamos la hoja del excel en donde están los datos, y también le indicamos el rango que son las columnas y filas que queremos ver. Esto siempre sigue el mismo formato: “COLUMNAFILA_INICIO:COLUMNAFILA_FINAL”. No necesariamente tienen que ser todas las columnas o filas, eso lo podemos cambiar según necesitemos.\n\nelsoc_2022 <- readxl::read_excel(path = \"input/data/ELSOC_W06_v1.0_EXCEL.xlsx\",\n                                 sheet = 1, # indicamos la hoja del excel,\n                                 range = \"A1:PU2731\")\n\nelsoc_2022\n\n# A tibble: 2,730 × 437\n   idencu…¹   ola version muestra cuest…² cuest…³ formato segme…⁴ comuna comun…⁵\n      <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>    <dbl>\n 1  1101011     6  202201       1       2       1       1  110101 Iquiq…    1101\n 2  1101012     6  202201       1       2       1       1  110101 Iquiq…    1101\n 3  1101023     6  202201       1       2       1       1  110102 Iquiq…    1101\n 4  1101041     6  202201       1       2       1       1  110104 Iquiq…    1101\n 5  1101081     6  202201       1       2       1       1  110108 Iquiq…    1101\n 6  1101082     6  202201       1       1       1       1  110108 Iquiq…    1101\n 7  1101102     6  202201       1       2       1       1  110110 San F…    6301\n 8  1101103     6  202201       1       1       1       1  110110 Iquiq…    1101\n 9  1101111     6  202201       1       2       1       1  110111 Iquiq…    1101\n10  1101113     6  202201       1       1       1       1  110111 Iquiq…    1101\n# … with 2,720 more rows, 427 more variables: region <chr>, region_cod <dbl>,\n#   estrato <dbl>, ponderador01 <dbl>, ponderador02 <dbl>, fact_exp01 <dbl>,\n#   fact_exp02 <dbl>, r05_01 <dbl>, r05_02 <dbl>, r06 <dbl>, r07 <dbl>,\n#   r08 <dbl>, r09 <dbl>, r10 <dbl>, r11 <dbl>, r12_01 <dbl>, r12_02 <dbl>,\n#   r12_03 <dbl>, r12_04 <dbl>, r12_05 <dbl>, r12_06 <dbl>, r12_07 <dbl>,\n#   r13_nredes <dbl>, r13_sexo_01 <dbl>, r13_edad_01 <dbl>,\n#   r13_relacion_01 <dbl>, r13_tiempo_01 <dbl>, r13_barrio_01 <dbl>, …\n\n\nSeleccionamos solo algunas columnas. Ahora vemos que solo tenemos 26 columnas:\n\nelsoc_2022 <- readxl::read_excel(path = \"input/data/ELSOC_W06_v1.0_EXCEL.xlsx\",\n                                 sheet = 1, # indicamos la hoja del excel,\n                                 range = \"A1:Z2731\")\n\nelsoc_2022\n\n# A tibble: 2,730 × 26\n   idencu…¹   ola version muestra cuest…² cuest…³ formato segme…⁴ comuna comun…⁵\n      <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>    <dbl>\n 1  1101011     6  202201       1       2       1       1  110101 Iquiq…    1101\n 2  1101012     6  202201       1       2       1       1  110101 Iquiq…    1101\n 3  1101023     6  202201       1       2       1       1  110102 Iquiq…    1101\n 4  1101041     6  202201       1       2       1       1  110104 Iquiq…    1101\n 5  1101081     6  202201       1       2       1       1  110108 Iquiq…    1101\n 6  1101082     6  202201       1       1       1       1  110108 Iquiq…    1101\n 7  1101102     6  202201       1       2       1       1  110110 San F…    6301\n 8  1101103     6  202201       1       1       1       1  110110 Iquiq…    1101\n 9  1101111     6  202201       1       2       1       1  110111 Iquiq…    1101\n10  1101113     6  202201       1       1       1       1  110111 Iquiq…    1101\n# … with 2,720 more rows, 16 more variables: region <chr>, region_cod <dbl>,\n#   estrato <dbl>, ponderador01 <dbl>, ponderador02 <dbl>, fact_exp01 <dbl>,\n#   fact_exp02 <dbl>, r05_01 <dbl>, r05_02 <dbl>, r06 <dbl>, r07 <dbl>,\n#   r08 <dbl>, r09 <dbl>, r10 <dbl>, r11 <dbl>, r12_01 <dbl>, and abbreviated\n#   variable names ¹​idencuesta, ²​cuestion_mig, ³​cuestion_completo, ⁴​segmento,\n#   ⁵​comuna_cod\n\n\n\n\n\nCuando los datos vienen en formato .R no es necesario asinarle un objeto, lo podemos hacer después de ser necesario. Para leer estos archivos usamos la función load() de R base.\n\nbase::load(file = \"input/data/ELSOC_W06_v1.0_R.RData\") \n\nelsoc_2022\n\n# A tibble: 2,730 × 437\n   idencu…¹   ola version muestra cuest…² cuest…³ formato segme…⁴ comuna comun…⁵\n      <dbl> <dbl>   <int>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>    <dbl>\n 1  1101011     6  202201       1       2       1       1  110101 Iquiq…    1101\n 2  1101012     6  202201       1       2       1       1  110101 Iquiq…    1101\n 3  1101023     6  202201       1       2       1       1  110102 Iquiq…    1101\n 4  1101041     6  202201       1       2       1       1  110104 Iquiq…    1101\n 5  1101081     6  202201       1       2       1       1  110108 Iquiq…    1101\n 6  1101082     6  202201       1       1       1       1  110108 Iquiq…    1101\n 7  1101102     6  202201       1       2       1       1  110110 San F…    6301\n 8  1101103     6  202201       1       1       1       1  110110 Iquiq…    1101\n 9  1101111     6  202201       1       2       1       1  110111 Iquiq…    1101\n10  1101113     6  202201       1       1       1       1  110111 Iquiq…    1101\n# … with 2,720 more rows, 427 more variables: region <chr>, region_cod <dbl>,\n#   estrato <dbl>, ponderador01 <dbl>, ponderador02 <dbl>, fact_exp01 <dbl>,\n#   fact_exp02 <dbl>, r05_01 <dbl>, r05_02 <dbl>, r06 <dbl>, r07 <dbl>,\n#   r08 <dbl>, r09 <dbl>, r10 <dbl>, r11 <dbl>, r12_01 <dbl>, r12_02 <dbl>,\n#   r12_03 <dbl>, r12_04 <dbl>, r12_05 <dbl>, r12_06 <dbl>, r12_07 <dbl>,\n#   r13_nredes <dbl>, r13_sexo_01 <dbl>, r13_edad_01 <dbl>,\n#   r13_relacion_01 <dbl>, r13_tiempo_01 <dbl>, r13_barrio_01 <dbl>, …"
  },
  {
    "objectID": "resource/04-resource.html",
    "href": "resource/04-resource.html",
    "title": "Procesamiento, limpieza y manipulación de datos en R",
    "section": "",
    "text": "El objetivo de esta guía práctica adicional es revisar algunos procedimientos básicos de la preparación de datos con R base, sirviendo como material complementario a lo apredendido en la sesión n° 3 del laboratorio."
  },
  {
    "objectID": "resource/04-resource.html#cargar-librerías",
    "href": "resource/04-resource.html#cargar-librerías",
    "title": "Procesamiento, limpieza y manipulación de datos en R",
    "section": "1 Cargar librerías",
    "text": "1 Cargar librerías\nEn R se trabaja a partir de paquetes (packages). ¿Qué son? De forma resumida, los paquetes son un conjunto de funciones o herramientas que pueden ser usadas en R. Los directorios de R donde se almacenan los paquetes se denominan librerías. La lógica es instalar paquetes y luego cargar (o llamar) las librerías cada vez que es necesario usarlas.\nUsualmente para cargar paquetes lo hacemos de la siguiente manera:\n\ninstall.packages(\"paquete\")\nlibrary(paquete)\n\nPero en esta ocasión utilizaremos un paquete llamado pacman, que facilita y agiliza la lectura (instalación y carga) de los paquetes a utilizar en R. De esta forma lo instalamos 1 única vez así:\n\ninstall.packages(\"pacman\")\nlibrary(pacman)\n\nLuego instalaremos y cargaremos los paquetes de R de la siguiente manera, volviendo más eficiente el procedimiento de carga de paquetes.\nEn este práctico utilizaremos seis paquetes\n\npacman: este facilita y agiliza la lectura de los paquetes a utilizar en R\ntidyverse: colección de paquetes, de la cual utilizaremos dplyr y haven\ndplyr: nos permite seleccionar variables de un set de datos\nhaven: cargar y exportar bases de datos en formatos .sav y .dta\ncar: para recodificar/agrupar valores de variables\nmagrittr: para manipular datos con %>%\n\n\npacman::p_load(tidyverse, # colección de paquetes para manipulación de datos\n               dplyr, # para manipular datos\n               haven, # para importar datos\n               car, # para recodificar datos\n               magrittr)# para manipular datos\n\noptions(scipen = 999) # para desactivar notacion cientifica\nrm(list = ls()) # para limpiar el entorno de trabajo\n\nComo se puede ver, antes de la función p_load hay un ::, esto se refiere a que se “fuerza” que esa función provenga de ese paquete (en este caso del paquete pacman)."
  },
  {
    "objectID": "resource/04-resource.html#importar-datos",
    "href": "resource/04-resource.html#importar-datos",
    "title": "Procesamiento, limpieza y manipulación de datos en R",
    "section": "2 Importar datos",
    "text": "2 Importar datos\nEn R es es posible importar y exportar datos que se encuentren en cualquier formato: ya sea .csv, .dta, .sav, .xlsx y, por supuesto, .rds y .RData. Sin embargo, para poder hacerlo lo primero es instalar y cargar las librerías que contienen las funciones necesarias para la importación de distintos tipos de archivos.\nPero, ¿dónde están mis datos? Como hemos mencionado, nuestros datos los dejaremos en la carpeta input/data de nuestro proyecto. La base con la que trabajaremos en este práctico pueden encontrarla en el material docente en U-Cursos, o bien, en el siguiente enlace.\nLuego de descargar la base de datos, asegurate de dejar el archivo .sav en la carpeta input/data de tu proyecto. Nota: Los datos tendrán distinto nombre según su formato (.sav, .csv, .dta, etc.).\nUna vez descargados los datos y cargado el paquete haven, procedemos a importar nuestra base de datos. Para ello, en nuestro script, dejamos indicado que a partir de la lectura de los datos con read_sav(), crearemos un objeto llamado elsoc_2022. Fijate en el Enviroment, ya que si lo anterior se logra, el objeto aparecerá allí.\nLa estructura general para importar datos es la siguiente:\nread_*(\"ruta_hacia_archivo/nombre_archivo.*\")\n\nelsoc_2022 <- read_sav(\"ELSOC W06 v1.0 SPSS.sav\")  # No funciona\n\nelsoc_2022 <- read_sav(\"input/data/ELSOC W06 v1.0 SPSS.sav\") # No funciona\n\nelsoc_2022 <- read_sav(\"input/data/ELSOC_W06_v1.0_SPSS.sav\") # Si funciona!\n\n\n\n\n\n\n\nNota\n\n\n\nPara importar los datos en R debemos tener en consideración tres cosas:\n\nCómo se llaman los datos (en nuestro caso ELSOC_W05_v1.0_SPSS)\nEl formato de nuestros datos (en nuestro caso .sav)\nEl lugar de donde están alojados nuestros datos\n\n\n\n\n2.1.1 Importar datos en otros formatos\nNo siempre nuestros datos vendrán en un único formato. Para ello, R cuenta con otras formas de leer distintos tipos de formatos. Puedes ver las principales en el siguiente enlace."
  },
  {
    "objectID": "resource/04-resource.html#explorar-datos",
    "href": "resource/04-resource.html#explorar-datos",
    "title": "Procesamiento, limpieza y manipulación de datos en R",
    "section": "3 Explorar datos",
    "text": "3 Explorar datos\nLo más probable es que no trabajemos con todos los datos que importamos, por lo que debemos seleccionar aquellas variables con las que trabajaremos para nuestro problema de investigación (cualquiera sea).\nPero, para ello primero debemos explorar nuestros datos, si no ¿cómo puedo saber qué seleccionar y qué no? En R, las funciones más comunes para explorar datos son:\n\nView(elsoc_2022) # Ver datos\nnames(elsoc_2022) # Nombre de columnas\ndim(elsoc_2022) # Dimensiones\nstr(elsoc_2022) # Estructura de los datos (las clases y categorias de repuesta)\n\nTenemos una base de datos con 1000 casos o filas y con 13 variables o columnas."
  },
  {
    "objectID": "resource/04-resource.html#limpiar-datos",
    "href": "resource/04-resource.html#limpiar-datos",
    "title": "Procesamiento, limpieza y manipulación de datos en R",
    "section": "4 Limpiar datos",
    "text": "4 Limpiar datos\nPara todos los subprocesos que involucra la “limpieza” de datos, tenemos al menos dos maneras. Por un lado, podemos usar las funciones de R base, es decir, que no requieren paquetes extras. Por el otro, podemos usar las funciones del paquete dplyr(), que es una gramática o dialecto de manipulación de datos que proporciona un conjunto de coherente funciones o “verbos” básicos para programar.\nEn este práctico nos centraremos solo en cómo manipular datos con el lenguaje de R base \n\n\n4.1 Seleccionar\nUna vez tenemos claras cúales son las variables que nos interesan, las seleccionamos y almacenamos en una nueva base de datos. Esto debido que evitará confusiones y hará más eficiente nuestros analísis en términos de memoria.\nEn R base, el primer argumento dentro del bracket [] refiere a las filas y el segundo a las columnas.\n\nelsoc_2022[ , 1] \n\n# A tibble: 1,000 × 1\n   m0_sexo\n   <chr>  \n 1 Hombre \n 2 Mujer  \n 3 Hombre \n 4 Hombre \n 5 Mujer  \n 6 Mujer  \n 7 Mujer  \n 8 Mujer  \n 9 Mujer  \n10 Hombre \n# … with 990 more rows\n\n\nTambién podemos seleccionar más de una columna/variable utilizando funciones básicas de R. Por ejemplo, usando c()\n\nelsoc_2022[, c(1,2,4)] #aqui le decimos que queremos las columnas especificas 1 2 y 4 \n\n# A tibble: 1,000 × 3\n   m0_sexo m0_edad   c25\n   <chr>     <dbl> <dbl>\n 1 Hombre       38     1\n 2 Mujer        45     1\n 3 Hombre       42     3\n 4 Hombre       29     1\n 5 Mujer        53     2\n 6 Mujer        52     3\n 7 Mujer        50     2\n 8 Mujer        57     1\n 9 Mujer        47     1\n10 Hombre       79     2\n# … with 990 more rows\n\n\nO bien, indicando desde qué columna hasta cuál quiero seleccionar.\n\nelsoc_2022[, 1:4] # aqui le decimos que queremos desde la columna 1 a la 4\n\n# A tibble: 1,000 × 4\n   m0_sexo m0_edad   m36   c25\n   <chr>     <dbl> <dbl> <dbl>\n 1 Hombre       38     1     1\n 2 Mujer        45     4     1\n 3 Hombre       42     4     3\n 4 Hombre       29     4     1\n 5 Mujer        53     5     2\n 6 Mujer        52     1     3\n 7 Mujer        50     4     2\n 8 Mujer        57     8     1\n 9 Mujer        47     4     1\n10 Hombre       79     4     2\n# … with 990 more rows\n\n\nY, obviamente, podemos utilizar el nombre de las variables.\n\nelsoc_2022[, c(\"m0_sexo\", \"m0_edad\")]\n\n# A tibble: 1,000 × 2\n   m0_sexo m0_edad\n   <chr>     <dbl>\n 1 Hombre       38\n 2 Mujer        45\n 3 Hombre       42\n 4 Hombre       29\n 5 Mujer        53\n 6 Mujer        52\n 7 Mujer        50\n 8 Mujer        57\n 9 Mujer        47\n10 Hombre       79\n# … with 990 more rows\n\n\nAhora, ¡apliquemos conocimientos! seleccionando y renombrando las variables de interés en un nueva base llamada proc_elsoc.\nEn este ejemplo utilizaremos las siguientes variables:\n\nm0_sexo: sexo del entrevistado\nm0_edad: edad del entrevistado\nm13: ingreso mensual entrevistado\nc25: preferencia entre autoritarismo y democracia\nf05_01: justificación violencia hacia delincuentes\n\n\nproc_elsoc <- elsoc_2022[, c(2,1,8,4,7)] # seleccionamos\n\nproc_elsoc\n\n# A tibble: 1,000 × 5\n   m0_edad m0_sexo     m13   c25 f05_01\n     <dbl> <chr>     <dbl> <dbl>  <dbl>\n 1      38 Hombre  4000000     1     NA\n 2      45 Mujer   2700000     1      3\n 3      42 Hombre   600000     3     NA\n 4      29 Hombre  1250000     1      1\n 5      53 Mujer    500000     2      3\n 6      52 Mujer        NA     3      2\n 7      50 Mujer        NA     2      5\n 8      57 Mujer         0     1      4\n 9      47 Mujer    600000     1      3\n10      79 Hombre       NA     2      1\n# … with 990 more rows\n\ncolnames(proc_elsoc) <- c(\"edad\", \"sexo\", \"ingreso\", \"autor_democ\", \"jv_delincuentes\") # renonbramos\n\nproc_elsoc\n\n# A tibble: 1,000 × 5\n    edad sexo   ingreso autor_democ jv_delincuentes\n   <dbl> <chr>    <dbl>       <dbl>           <dbl>\n 1    38 Hombre 4000000           1              NA\n 2    45 Mujer  2700000           1               3\n 3    42 Hombre  600000           3              NA\n 4    29 Hombre 1250000           1               1\n 5    53 Mujer   500000           2               3\n 6    52 Mujer       NA           3               2\n 7    50 Mujer       NA           2               5\n 8    57 Mujer        0           1               4\n 9    47 Mujer   600000           1               3\n10    79 Hombre      NA           2               1\n# … with 990 more rows\n\n\nEsta nueva base de datos sigue manteniendo los 1.000 casos/filas, pero ahora solo tiene 5 variables/columnas. ¿Qué pasa si solo quiero trabajar con un subconjunto de estos datos, por ejemplo, las mujeres mayores a 25 años? La respuesta es filtrar.\n\n\n4.2 Filtrar\nTal y como regularmente no trabajamos con todas las variables de una base de datos, no siempre desearemos trabajar con todas las observaciones que tenemos en los datos. Habrá ocasiones (varias) en las que querremos trabajar con casos que cumplan ciertas condiciones; que sean de determinada edad, residencia, tiempo o que simplemente hayan respondido de determinada forma una pregunta.\nAhora, en vez de trabajar con columnas trabajaremos con las filas. Esto lo haremos especificando condiciones de las variables en el primer argumento de los brackets [].\n\nproc_elsoc[proc_elsoc$autor_democ == 1, ] # indicamos que en nuestra base proc_elsoc, queremos que nos deje aquellos casos que cumplen con la condicion de que autor_democr sea 2\n\n# A tibble: 552 × 5\n    edad sexo   ingreso autor_democ jv_delincuentes\n   <dbl> <chr>    <dbl>       <dbl>           <dbl>\n 1    38 Hombre 4000000           1              NA\n 2    45 Mujer  2700000           1               3\n 3    29 Hombre 1250000           1               1\n 4    57 Mujer        0           1               4\n 5    47 Mujer   600000           1               3\n 6    39 Hombre 1350000           1               4\n 7    61 Mujer       NA           1               3\n 8    25 Hombre      NA           1               2\n 9    42 Hombre 1100000           1               4\n10    51 Hombre  800000           1               1\n# … with 542 more rows\n\n\nPara indicarle a R que nos filtre aquellos casos que cumplen con la condición de ser iguales a 1 (autor_democ == 1), usamos el operador ==. ¿Y esto de dónde salió? recuerda que los operadores en R los vimos en la segunda sesión.\nTambién podemos agregar muchas condiciones para filtrar nuestros datos. Solamente debemos agregarlo.\n\nproc_elsoc[proc_elsoc$autor_democ == 1 & proc_elsoc$edad >= 25, ] # aqui le indicamos que nos filtre por casos que son autoritarismo/democracia igual 2 (no confia) y mayores o iguales a 25 años\n\n# A tibble: 544 × 5\n    edad sexo   ingreso autor_democ jv_delincuentes\n   <dbl> <chr>    <dbl>       <dbl>           <dbl>\n 1    38 Hombre 4000000           1              NA\n 2    45 Mujer  2700000           1               3\n 3    29 Hombre 1250000           1               1\n 4    57 Mujer        0           1               4\n 5    47 Mujer   600000           1               3\n 6    39 Hombre 1350000           1               4\n 7    61 Mujer       NA           1               3\n 8    25 Hombre      NA           1               2\n 9    42 Hombre 1100000           1               4\n10    51 Hombre  800000           1               1\n# … with 534 more rows\n\n\nPero, ¿y si tengo variables tipo character o factor? Tanto en R base como con dplyr podemos especificar condiciones y filtrar este tipo de datos usando las comillas \" \".\n\nproc_elsoc[proc_elsoc$sexo == \"Mujer\", ] \n\n# A tibble: 656 × 5\n    edad sexo  ingreso autor_democ jv_delincuentes\n   <dbl> <chr>   <dbl>       <dbl>           <dbl>\n 1    45 Mujer 2700000           1               3\n 2    53 Mujer  500000           2               3\n 3    52 Mujer      NA           3               2\n 4    50 Mujer      NA           2               5\n 5    57 Mujer       0           1               4\n 6    47 Mujer  600000           1               3\n 7    61 Mujer      NA           1               3\n 8    78 Mujer      NA           4               1\n 9    65 Mujer      NA           1               1\n10    69 Mujer      NA           2               1\n# … with 646 more rows\n\n\n¡Apliquémos conocimientos! Filtremos nuestros datos quedándonos solo con aquellos casos o personas que tengan o sean mayores a 25 años de edad.\n\nproc_elsoc <- proc_elsoc[proc_elsoc$edad >= 25, ] \n\nproc_elsoc\n\n# A tibble: 980 × 5\n    edad sexo   ingreso autor_democ jv_delincuentes\n   <dbl> <chr>    <dbl>       <dbl>           <dbl>\n 1    38 Hombre 4000000           1              NA\n 2    45 Mujer  2700000           1               3\n 3    42 Hombre  600000           3              NA\n 4    29 Hombre 1250000           1               1\n 5    53 Mujer   500000           2               3\n 6    52 Mujer       NA           3               2\n 7    50 Mujer       NA           2               5\n 8    57 Mujer        0           1               4\n 9    47 Mujer   600000           1               3\n10    79 Hombre      NA           2               1\n# … with 970 more rows\n\n\n\n\n4.3 Recodificar\nUna parte fundamental del procesamiento e integración de datos es la recodificación de variables. Esto implica que, a determinadas variables, le aplicaremos ciertos cambios de acuerdo a ciertas reglas y criterios establecidos con anterioridad, siempre cuidando la coherencia con nuestro objetivo de investigación.\nHay múltiples formas de recodificar en R, pero en este ejemplo trabajaremos con el comando recode() del paquete car.\nEsta vez, recodificaremos las siguientes variables: sexo, ingreso, autor_democ y jv_delincuentes. Para esto, nos apoyaremos en el libro de códigos.\n\n\n\n\n\n\nTip\n\n\n\nEl comando recode() generalmente sigue esta estructura:\ncar::recode(datos$variable, recodes = c('valor_orig1=nuevo_valor1;valor_org2=nuevo_valor2'))\n\n\nRecodifiquemos la variable sexo e ingresos:\n\nproc_elsoc$sexo <- car::recode(proc_elsoc$sexo, \n                               recodes = c(\"'Hombre' = 'Masculino'; 'Mujer' = 'Femenino'\"))\n\nproc_elsoc$ingreso <- car::recode(proc_elsoc$ingreso,\n                                  recodes = c(\"-888 = NA; -999 = NA\"))\n\nproc_elsoc\n\n# A tibble: 980 × 5\n    edad sexo      ingreso autor_democ jv_delincuentes\n   <dbl> <chr>       <dbl>       <dbl>           <dbl>\n 1    38 Masculino 4000000           1              NA\n 2    45 Femenino  2700000           1               3\n 3    42 Masculino  600000           3              NA\n 4    29 Masculino 1250000           1               1\n 5    53 Femenino   500000           2               3\n 6    52 Femenino       NA           3               2\n 7    50 Femenino       NA           2               5\n 8    57 Femenino        0           1               4\n 9    47 Femenino   600000           1               3\n10    79 Masculino      NA           2               1\n# … with 970 more rows\n\n\nAhora recodifiquemos las demás variables. Además de recodificar valores propiamente tal, con recode() podemos indicarle, en la misma función, que convierta la variable a factor y/o que le asigne niveles (ej. para variables ordinales).\n\nproc_elsoc$autor_democ <- car::recode(proc_elsoc$autor_democ, \n            recodes = c(\"1 = 'La democracia es preferible a cualquier otra forma de gobierno'; \n                        2 = 'En algunas circunstancias, un gobierno autoritario puede ser preferible a uno democratico'; \n                        3 = 'A la gente como uno, nos da lo mismo un regimen democratico que uno autoritario'; \n                        4 = 'Ninguna'; \n                        -888 = NA; \n                        -999 = NA\"),\n            as.factor = TRUE) # convertir a factor\n\nproc_elsoc$jv_delincuentes <- car::recode(proc_elsoc$jv_delincuentes, \n                                          recodes = c(\"1 = 'Nunca';\n                                                       2 = 'Pocas veces';\n                                                       3 = 'Algunas veces';\n                                                       4 = 'Muchas veces';\n                                                       5 = 'Siempre';\n                                                       -888 = NA; \n                                                       -999 = NA\"),\n                                          as.factor = TRUE, # convertir a factor\n                                          levels = c(\"Nunca\",\n                                                     \"Pocas veces\",\n                                                     \"Algunas veces\",\n                                                     \"Muchas veces\",\n                                                     \"Siempre\")) # ordenamos niveles\n\nproc_elsoc\n\n# A tibble: 980 × 5\n    edad sexo      ingreso autor_democ                                   jv_de…¹\n   <dbl> <chr>       <dbl> <fct>                                         <fct>  \n 1    38 Masculino 4000000 La democracia es preferible a cualquier otra… <NA>   \n 2    45 Femenino  2700000 La democracia es preferible a cualquier otra… Alguna…\n 3    42 Masculino  600000 A la gente como uno, nos da lo mismo un regi… <NA>   \n 4    29 Masculino 1250000 La democracia es preferible a cualquier otra… Nunca  \n 5    53 Femenino   500000 En algunas circunstancias, un gobierno autor… Alguna…\n 6    52 Femenino       NA A la gente como uno, nos da lo mismo un regi… Pocas …\n 7    50 Femenino       NA En algunas circunstancias, un gobierno autor… Siempre\n 8    57 Femenino        0 La democracia es preferible a cualquier otra… Muchas…\n 9    47 Femenino   600000 La democracia es preferible a cualquier otra… Alguna…\n10    79 Masculino      NA En algunas circunstancias, un gobierno autor… Nunca  \n# … with 970 more rows, and abbreviated variable name ¹​jv_delincuentes\n\n\n\n\n\n\n\n\nNota\n\n\n\nComo se puede ver, los valores -888 y -999 fueron codificados como valores pérdidos ya que estos valores significan no sabe y no responde, respectivamente.\n\n\n\n\n4.4 Tratamiento casos pérdidos\nComúnmente, los datos con los que trabajamos suelen tener valores pérdidos o nulos que en R se denominan como NA. Estos valores no nos entregan información útil para nuestros análisis, y pueden generar problemas al momento de, por ejemplo, calcular medidas de tendencia central, u otros procedimientos estadísticos.\nHay diversas maneras de trabajar los valores nulos. Sin embargo, la más sencilla consiste en eliminar los valores nulos que se encuentran presentes en nuestros datos.\nEl primer paso es identificar valores nulos en el conjunto de datos en general, o en alguna variable en específico. Para ello, empleamos la función is.na().\n\nis.na(proc_elsoc)\n\nis.na(proc_elsoc$ingreso)\n\nPero esto es poco útil. Como opción, podemos sumar o contar la cantidad de valores pérdidos.\n\nsum(is.na(proc_elsoc))\n\n[1] 515\n\n\n¿Y si no sabemos qué variables o columnas tienen casos pérdidos? Una forma es usar la función colSums().\n\ncolSums(is.na(proc_elsoc))\n\n           edad            sexo         ingreso     autor_democ jv_delincuentes \n              0               0             435              13              67 \n\n\nUna vez identificamos los valores nulos, podemos proceder a removerlos de la base de datos. El comando na.omit() eliminará todas las filas que presenten casos perdidos.\n\nproc_elsoc <- na.omit(proc_elsoc)\n\nproc_elsoc\n\n# A tibble: 496 × 5\n    edad sexo      ingreso autor_democ                                   jv_de…¹\n   <dbl> <chr>       <dbl> <fct>                                         <fct>  \n 1    45 Femenino  2700000 La democracia es preferible a cualquier otra… Alguna…\n 2    29 Masculino 1250000 La democracia es preferible a cualquier otra… Nunca  \n 3    53 Femenino   500000 En algunas circunstancias, un gobierno autor… Alguna…\n 4    57 Femenino        0 La democracia es preferible a cualquier otra… Muchas…\n 5    47 Femenino   600000 La democracia es preferible a cualquier otra… Alguna…\n 6    39 Masculino 1350000 La democracia es preferible a cualquier otra… Muchas…\n 7    42 Masculino 1100000 La democracia es preferible a cualquier otra… Muchas…\n 8    51 Masculino  800000 La democracia es preferible a cualquier otra… Nunca  \n 9    38 Masculino 1600000 A la gente como uno, nos da lo mismo un regi… Alguna…\n10    45 Femenino   500000 La democracia es preferible a cualquier otra… Nunca  \n# … with 486 more rows, and abbreviated variable name ¹​jv_delincuentes"
  },
  {
    "objectID": "resource/04-resource.html#transformar-variables",
    "href": "resource/04-resource.html#transformar-variables",
    "title": "Procesamiento, limpieza y manipulación de datos en R",
    "section": "5 Transformar variables",
    "text": "5 Transformar variables\nUn último paso en el procesamiento de datos es la creación o derivación de nuevas variables a partir de los datos que ya tenemos. Esto es relevante no solo para procesar datos, sino porque permite generar variables que se alineen mucho mejor con nuestros objetivos de análisis.\nEn este ejemplo, transformaremos las variables edad e ingresos, y crearemos una nueva variable llamada año de la encuesta y otra llamada ingreso_minimo.\n¡Veámos cómo se hace!\nGeneremos las nueva variable año:\n\nproc_elsoc$ano <- 2022\n\nproc_elsoc\n\nGeneremos nuevas variables para edad e ingresos dejándolas como tramos con ifelse().\n\nproc_elsoc$tramo_edad <- ifelse(proc_elsoc$edad <= 29, \"Jovenes\", proc_elsoc$edad)\nproc_elsoc$tramo_edad <- ifelse(proc_elsoc$edad >= 30 & proc_elsoc$edad <= 59, \"Adultos\", proc_elsoc$tramo_edad)\nproc_elsoc$tramo_edad <- ifelse(proc_elsoc$edad >= 60, \"Adultos mayores\", proc_elsoc$tramo_edad)\n\nproc_elsoc$tramo_ingreso <- ifelse(proc_elsoc$ingreso <= 250000, \"Tramo 1\", proc_elsoc$ingreso)\nproc_elsoc$tramo_ingreso <- ifelse(proc_elsoc$ingreso > 250000 & proc_elsoc$ingreso <= 500000, \"Tramo 2\", proc_elsoc$tramo_ingreso)\nproc_elsoc$tramo_ingreso <- ifelse(proc_elsoc$ingreso > 500000 & proc_elsoc$ingreso <= 750000, \"Tramo 3\", proc_elsoc$tramo_ingreso)\nproc_elsoc$tramo_ingreso <- ifelse(proc_elsoc$ingreso > 750000 & proc_elsoc$ingreso <= 1000000, \"Tramo 4\", proc_elsoc$tramo_ingreso)\nproc_elsoc$tramo_ingreso <- ifelse(proc_elsoc$ingreso > 1000000, \"Tramo 5\", proc_elsoc$tramo_ingreso)\n\nproc_elsoc\n\n# A tibble: 496 × 7\n    edad sexo      ingreso autor_democ                   jv_de…¹ tramo…² tramo…³\n   <dbl> <chr>       <dbl> <fct>                         <fct>   <chr>   <chr>  \n 1    45 Femenino  2700000 La democracia es preferible … Alguna… Adultos Tramo 5\n 2    29 Masculino 1250000 La democracia es preferible … Nunca   Jovenes Tramo 5\n 3    53 Femenino   500000 En algunas circunstancias, u… Alguna… Adultos Tramo 2\n 4    57 Femenino        0 La democracia es preferible … Muchas… Adultos Tramo 1\n 5    47 Femenino   600000 La democracia es preferible … Alguna… Adultos Tramo 3\n 6    39 Masculino 1350000 La democracia es preferible … Muchas… Adultos Tramo 5\n 7    42 Masculino 1100000 La democracia es preferible … Muchas… Adultos Tramo 5\n 8    51 Masculino  800000 La democracia es preferible … Nunca   Adultos Tramo 4\n 9    38 Masculino 1600000 A la gente como uno, nos da … Alguna… Adultos Tramo 5\n10    45 Femenino   500000 La democracia es preferible … Nunca   Adultos Tramo 2\n# … with 486 more rows, and abbreviated variable names ¹​jv_delincuentes,\n#   ²​tramo_edad, ³​tramo_ingreso\n\n\nAhora, generemos una nueva variable llamada ingreso_minimo con la función ifelse().\n\nproc_elsoc$ingreso_minimo <- ifelse(proc_elsoc$ingreso < 410000, \"debajo minimo\", \"sobre minimo\")\n\nproc_elsoc[, c(\"ingreso\", \"ingreso_minimo\")] #veamosla!\n\n# A tibble: 496 × 2\n   ingreso ingreso_minimo\n     <dbl> <chr>         \n 1 2700000 sobre minimo  \n 2 1250000 sobre minimo  \n 3  500000 sobre minimo  \n 4       0 debajo minimo \n 5  600000 sobre minimo  \n 6 1350000 sobre minimo  \n 7 1100000 sobre minimo  \n 8  800000 sobre minimo  \n 9 1600000 sobre minimo  \n10  500000 sobre minimo  \n# … with 486 more rows"
  },
  {
    "objectID": "resource/04-resource.html#guardar-y-exportar-datos-procesados",
    "href": "resource/04-resource.html#guardar-y-exportar-datos-procesados",
    "title": "Procesamiento, limpieza y manipulación de datos en R",
    "section": "7 Guardar y exportar datos procesados",
    "text": "7 Guardar y exportar datos procesados\n¡Legamos al final! El último paso que nos queda es guardar y exportar nuestra base de datos procesada. Siguiendo el flujo de trabajo propuesto, guardaremos la base procesada en formato .Rdata y la alojaremos en la carpeta output de nuestro proyecto.\nEste último paso es bastante sencillo, solo debemos especificar la base que queremos guadar y su ruta:\n\nsaveRDS(proc_elsoc, file = \"output/datos_proc.Rdata\")"
  },
  {
    "objectID": "resource/05-resource.html",
    "href": "resource/05-resource.html",
    "title": "Análisis Factorial Exploratorio",
    "section": "",
    "text": "pacman::p_load(stargazer, # Reporte\nsjPlot, sjmisc, # reporte y gráficos\nsjlabelled,\ncorrplot, # grafico correlaciones\nxtable, # Reporte\nHmisc, # varias funciones\npsych, # fa y principal factors\npsy, # scree plot function\nnFactors, # parallel\nGPArotation) # rotación\n\nInstalling package into '/Users/macbookair/Downloads/encuestas-sociales-main/renv/library/R-4.2/aarch64-apple-darwin20'\n(as 'lib' is unspecified)\n\n\nalso installing the dependency 'htmlTable'\n\n\n\nHmisc installed\n\n\nInstalling package into '/Users/macbookair/Downloads/encuestas-sociales-main/renv/library/R-4.2/aarch64-apple-darwin20'\n(as 'lib' is unspecified)\n\n\n\npsy installed\n\n\nInstalling package into '/Users/macbookair/Downloads/encuestas-sociales-main/renv/library/R-4.2/aarch64-apple-darwin20'\n(as 'lib' is unspecified)\n\n\n\nnFactors installed\n\n\nInstalling package into '/Users/macbookair/Downloads/encuestas-sociales-main/renv/library/R-4.2/aarch64-apple-darwin20'\n(as 'lib' is unspecified)\n\n\n\nGPArotation installed\n\n\n\n\n\nLectura de datos\n\ndata <- read.csv(\"input/data/efa_asignaturas.csv\")\n\n\n\n\n\nMuestra de 300 alumnos a los que se le pregunta por su asignatura favorita en una escala de 1 (no me agrada) a 5 (me agrada)\n\n\n\n\n\nsummary(data)\n\n      BIO             GEO            CHEM            ALG            CALC      \n Min.   :1.000   Min.   :1.00   Min.   :1.000   Min.   :1.00   Min.   :1.000  \n 1st Qu.:1.000   1st Qu.:1.00   1st Qu.:1.000   1st Qu.:2.00   1st Qu.:2.000  \n Median :2.000   Median :2.00   Median :2.000   Median :3.00   Median :3.000  \n Mean   :2.353   Mean   :2.17   Mean   :2.237   Mean   :3.05   Mean   :3.063  \n 3rd Qu.:3.000   3rd Qu.:3.00   3rd Qu.:3.000   3rd Qu.:4.00   3rd Qu.:4.000  \n Max.   :5.000   Max.   :5.00   Max.   :5.000   Max.   :5.00   Max.   :5.000  \n      STAT      \n Min.   :1.000  \n 1st Qu.:2.000  \n Median :3.000  \n Mean   :2.937  \n 3rd Qu.:4.000  \n Max.   :5.000  \n\nnames(data)\n\n[1] \"BIO\"  \"GEO\"  \"CHEM\" \"ALG\"  \"CALC\" \"STAT\"\n\ndim(data)  # filas columnas\n\n[1] 300   6\n\nnrow(na.omit(data)) # número de casos con datos completos\n\n[1] 300"
  },
  {
    "objectID": "resource/05-resource.html#gráfico-barras-apiladas",
    "href": "resource/05-resource.html#gráfico-barras-apiladas",
    "title": "Análisis Factorial Exploratorio",
    "section": "Gráfico barras apiladas",
    "text": "Gráfico barras apiladas\n\n#sjplot(data$BIO, \"frq\") # no muy buena descripción ...\n\nnames(data)\n\n[1] \"BIO\"  \"GEO\"  \"CHEM\" \"ALG\"  \"CALC\" \"STAT\"\n\nplot_stackfrq(data)\n\n\n\n\nGráfico final\n\n#label values\n\ndata <- data %>%  set_labels (., labels=c(\"No le agrada\"=1,\n  \"Le agrada\"=5))\n\nplot_stackfrq(data, sort.frq = \"last.desc\", geom.colors = \"OrRd\") #+ theme(legend.position=\"bottom\")"
  },
  {
    "objectID": "resource/05-resource.html#analisis-de-matriz-de-correlaciones",
    "href": "resource/05-resource.html#analisis-de-matriz-de-correlaciones",
    "title": "Análisis Factorial Exploratorio",
    "section": "Analisis de matriz de correlaciones",
    "text": "Analisis de matriz de correlaciones\nMatriz\n\ncorMat  <- cor(data)  # estimar matriz pearson\noptions(digits=2)\ncorMat # muestra matriz\n\n      BIO  GEO  CHEM   ALG CALC STAT\nBIO  1.00 0.68 0.747 0.115 0.21 0.20\nGEO  0.68 1.00 0.681 0.135 0.20 0.23\nCHEM 0.75 0.68 1.000 0.084 0.14 0.17\nALG  0.12 0.14 0.084 1.000 0.77 0.41\nCALC 0.21 0.20 0.136 0.771 1.00 0.51\nSTAT 0.20 0.23 0.166 0.409 0.51 1.00\n\n\nReporte tabla\n\ntab_corr(data, triangle = \"lower\")\n\n\n\n\n \nBIO\nGEO\nCHEM\nALG\nCALC\nSTAT\n\n\nBIO\n \n \n \n \n \n \n\n\nGEO\n0.682***\n \n \n \n \n \n\n\nCHEM\n0.747***\n0.681***\n \n \n \n \n\n\nALG\n0.115*\n0.135*\n0.084\n \n \n \n\n\nCALC\n0.213***\n0.205***\n0.136*\n0.771***\n \n \n\n\nSTAT\n0.203***\n0.232***\n0.166**\n0.409***\n0.507***\n \n\n\nComputed correlation used pearson-method with listwise-deletion.\n\n \n\n\n\nReporte gráfico con corrplot\n\nM=cor(data) # matriz simple de correlaciones de los datos\ncorrplot(M, type=\"lower\") # lower x bajo diagonal\n\n\n\n\nOtra opción\n\ncorrplot(M, type=\"lower\",\n      order=\"AOE\", cl.pos=\"b\", tl.pos=\"d\") #agrega nombres en diag."
  },
  {
    "objectID": "resource/05-resource.html#seleccion-de-numero-de-factores",
    "href": "resource/05-resource.html#seleccion-de-numero-de-factores",
    "title": "Análisis Factorial Exploratorio",
    "section": "Seleccion de numero de factores",
    "text": "Seleccion de numero de factores\nGraficos\n\nscree.plot(data)\n\n\n\n\n\nfa.parallel(corMat, n.obs=300)\n\n\n\n\nParallel analysis suggests that the number of factors =  2  and the number of components =  2 \n\n\n\nlibrary(nFactors)\nev <- eigen(corMat) # get eigenvalues\nap <- parallel(subject=300,var=6,\n  rep=100,cent=.05)\nnS <- nScree(x=ev$values, aparallel=ap$eigen$qevpea)\nplotnScree(nS)\n\n\n\n\nFactor de aceleración: solución numérica que muestra el punto que presenta el mayor cambio de pendiente\nOptimal coordinates: muestra el primer eigenvalue que puede ser mejor “extrapolado” desde el eigenvalue previo (“optimal coordinates are the extrapolated coordinates of the previous eigenvalue that allow the observed eigenvalue to go beyond this extrapolation” (http://www.inside-r.org/packages/cran/nFactors/docs/nScree)"
  },
  {
    "objectID": "resource/05-resource.html#extracción",
    "href": "resource/05-resource.html#extracción",
    "title": "Análisis Factorial Exploratorio",
    "section": "Extracción",
    "text": "Extracción\nEjes principales\n\nfac_pa <- fa(r = data, nfactors = 2, fm= \"pa\")\n#summary(fac_pa)\nfac_pa\n\nFactor Analysis using method =  pa\nCall: fa(r = data, nfactors = 2, fm = \"pa\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n       PA1   PA2   h2    u2 com\nBIO   0.86  0.02 0.75 0.255 1.0\nGEO   0.78  0.05 0.63 0.369 1.0\nCHEM  0.87 -0.05 0.75 0.253 1.0\nALG  -0.04  0.81 0.65 0.354 1.0\nCALC  0.01  0.96 0.92 0.081 1.0\nSTAT  0.13  0.50 0.29 0.709 1.1\n\n                       PA1  PA2\nSS loadings           2.14 1.84\nProportion Var        0.36 0.31\nCumulative Var        0.36 0.66\nProportion Explained  0.54 0.46\nCumulative Proportion 0.54 1.00\n\n With factor correlations of \n     PA1  PA2\nPA1 1.00 0.21\nPA2 0.21 1.00\n\nMean item complexity =  1\nTest of the hypothesis that 2 factors are sufficient.\n\ndf null model =  15  with the objective function =  2.9 with Chi Square =  849\ndf of  the model are 4  and the objective function was  0.01 \n\nThe root mean square of the residuals (RMSR) is  0.01 \nThe df corrected root mean square of the residuals is  0.02 \n\nThe harmonic n.obs is  300 with the empirical chi square  0.78  with prob <  0.94 \nThe total n.obs was  300  with Likelihood Chi Square =  3.3  with prob <  0.51 \n\nTucker Lewis Index of factoring reliability =  1\nRMSEA index =  0  and the 90 % confidence intervals are  0 0.08\nBIC =  -20\nFit based upon off diagonal values = 1\nMeasures of factor score adequacy             \n                                                   PA1  PA2\nCorrelation of (regression) scores with factors   0.94 0.96\nMultiple R square of scores with factors          0.88 0.93\nMinimum correlation of possible factor scores     0.77 0.86\n\n\nMaximum likelihood\n\nfac_ml <- fa(r = data, nfactors = 2, fm= \"ml\")\nsummary(fac_ml)\n\nPlot de cargas factoriales ml\n\nfactor.plot(fac_ml, labels=rownames(fac_ml$loadings))\n\n\n\n\nObtención de Puntajes factoriales\nLos puntajes factoriales son vectores/variables que representan al factor latente como una variable observada y que por lo tanto suma una columna a la base de datos por cada factor extraído. Como la variable latente no tiene métrica, se le otorga una con media 0 y varianza 1. Los puntajes son una especie de índice pero donde la constribución de cada indicador al índice se encuentra ponderada por su carga factorial (su contribución a la variable latente común o factor).\n\nfac_ml <- fa(r = data, nfactors = 2, fm= \"ml\", scores=\"regression\")\ndata2=data\ndata3 <- cbind(data2, fac_ml$scores)\nhead(data3)\n\n  BIO GEO CHEM ALG CALC STAT    ML2   ML1\n1   1   1    1   1    1    1 -1.110 -1.84\n2   4   4    3   4    4    4  1.153  0.85\n3   2   1    3   4    1    1 -0.188 -1.61\n4   2   3    2   4    4    3 -0.013  0.82\n5   3   1    2   2    3    4 -0.070 -0.11\n6   1   1    1   4    4    4 -1.022  0.84"
  },
  {
    "objectID": "resource/05-resource.html#rotación",
    "href": "resource/05-resource.html#rotación",
    "title": "Análisis Factorial Exploratorio",
    "section": "Rotación",
    "text": "Rotación\nVarimax (ortogonal)\n\nfac_ml_var <- fa(r = data, nfactors = 2, fm= \"ml\", rotate=\"varimax\") # ortogonal\nfac_ml_var\n\nFactor Analysis using method =  ml\nCall: fa(r = data, nfactors = 2, rotate = \"varimax\", fm = \"ml\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n      ML2  ML1   h2    u2 com\nBIO  0.85 0.13 0.75 0.252 1.0\nGEO  0.78 0.13 0.63 0.375 1.1\nCHEM 0.86 0.06 0.75 0.249 1.0\nALG  0.03 0.79 0.63 0.374 1.0\nCALC 0.10 0.97 0.95 0.048 1.0\nSTAT 0.17 0.51 0.29 0.715 1.2\n\n                       ML2  ML1\nSS loadings           2.12 1.86\nProportion Var        0.35 0.31\nCumulative Var        0.35 0.66\nProportion Explained  0.53 0.47\nCumulative Proportion 0.53 1.00\n\nMean item complexity =  1.1\nTest of the hypothesis that 2 factors are sufficient.\n\ndf null model =  15  with the objective function =  2.9 with Chi Square =  849\ndf of  the model are 4  and the objective function was  0.01 \n\nThe root mean square of the residuals (RMSR) is  0.01 \nThe df corrected root mean square of the residuals is  0.02 \n\nThe harmonic n.obs is  300 with the empirical chi square  0.97  with prob <  0.91 \nThe total n.obs was  300  with Likelihood Chi Square =  2.9  with prob <  0.57 \n\nTucker Lewis Index of factoring reliability =  1\nRMSEA index =  0  and the 90 % confidence intervals are  0 0.076\nBIC =  -20\nFit based upon off diagonal values = 1\nMeasures of factor score adequacy             \n                                                   ML2  ML1\nCorrelation of (regression) scores with factors   0.94 0.98\nMultiple R square of scores with factors          0.88 0.95\nMinimum correlation of possible factor scores     0.76 0.91\n\n\nPromax (oblicua)\n\nfac_ml_pro <- fa(r = data, nfactors = 2, fm= \"ml\", rotate=\"promax\")\nfac_ml_pro\n\nFactor Analysis using method =  ml\nCall: fa(r = data, nfactors = 2, rotate = \"promax\", fm = \"ml\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n       ML2   ML1   h2    u2 com\nBIO   0.86  0.02 0.75 0.252 1.0\nGEO   0.78  0.03 0.63 0.375 1.0\nCHEM  0.88 -0.06 0.75 0.249 1.0\nALG  -0.09  0.81 0.63 0.374 1.0\nCALC -0.05  0.99 0.95 0.048 1.0\nSTAT  0.10  0.50 0.29 0.715 1.1\n\n                       ML2  ML1\nSS loadings           2.12 1.86\nProportion Var        0.35 0.31\nCumulative Var        0.35 0.66\nProportion Explained  0.53 0.47\nCumulative Proportion 0.53 1.00\n\n With factor correlations of \n     ML2  ML1\nML2 1.00 0.28\nML1 0.28 1.00\n\nMean item complexity =  1\nTest of the hypothesis that 2 factors are sufficient.\n\ndf null model =  15  with the objective function =  2.9 with Chi Square =  849\ndf of  the model are 4  and the objective function was  0.01 \n\nThe root mean square of the residuals (RMSR) is  0.01 \nThe df corrected root mean square of the residuals is  0.02 \n\nThe harmonic n.obs is  300 with the empirical chi square  0.97  with prob <  0.91 \nThe total n.obs was  300  with Likelihood Chi Square =  2.9  with prob <  0.57 \n\nTucker Lewis Index of factoring reliability =  1\nRMSEA index =  0  and the 90 % confidence intervals are  0 0.076\nBIC =  -20\nFit based upon off diagonal values = 1\nMeasures of factor score adequacy             \n                                                   ML2  ML1\nCorrelation of (regression) scores with factors   0.94 0.98\nMultiple R square of scores with factors          0.89 0.96\nMinimum correlation of possible factor scores     0.77 0.91"
  },
  {
    "objectID": "resource/05-resource.html#reporte-tabla-análisis-factorial",
    "href": "resource/05-resource.html#reporte-tabla-análisis-factorial",
    "title": "Análisis Factorial Exploratorio",
    "section": "Reporte: Tabla análisis factorial",
    "text": "Reporte: Tabla análisis factorial\nA html via sjPlot\n\ntab_fa(data, rotation = \"varimax\",show.comm = TRUE, title = \"Análisis factorial asignaturas\")\n\nParallel analysis suggests that the number of factors =  2  and the number of components =  NA \n\n\n\n\nAnálisis factorial asignaturas\n\n \nFactor 1\nFactor 2\nCommunality\n\n\nBIO\n0.85\n0.13\n0.75\n\n\nGEO\n0.78\n0.13\n0.63\n\n\nCHEM\n0.86\n0.06\n0.75\n\n\nALG\n0.03\n0.79\n0.63\n\n\nCALC\n0.10\n0.97\n0.95\n\n\nSTAT\n0.17\n0.51\n0.29\n\n\nTotal Communalities\n\n3.99\n\n\nCronbach's α\n0.88\n0.79"
  },
  {
    "objectID": "resource/index.html",
    "href": "resource/index.html",
    "title": "Recursos adicionales",
    "section": "",
    "text": "En esta sección se presentan una serie de recursos como ejemplos de bases de datos, tutoriales, guías y sitios de consulta sobre el uso de R."
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Planificación",
    "section": "",
    "text": "Los dos componentes centrales del curso son las clases lectivas y las sesiones de Laboratorio de Análisis de Datos. Las clases se realizarán los días Jueves 08:30 a 11:45  en sala sala 7 y 8 del Aulario A, mientras que las sesiones de Laboratorio se realizarán los días Jueves 08:30 a 11:45  vía Zoom con una periodicidad de cada 2 semanas.\n\nClases ( ): Documentos de presentación y lecturas asociadas.\nPrácticas (): Actividades prácticas en Laboratorio de Análisis de Datos a desarrollar durante el semestre.\nEvaluaciones (): Evaluaciones individuales y colectivas a desarrollar durante el semestre.\n\n\n\n\n\n Clases\n Prácticas\n Evaluaciones\n\n\n\n\n Marzo \n\n\n\n\n\nJueves 16\n1. Presentación e introducción\n\n- Leer detalladamente programa del curso\n\n\n\n\nUNIDAD 1: Sociología y estadística\n\n\n\nJueves 23\n2. Caracterización de la investigación cuantitativa\n\n\n\n\nJueves 30\n3. La medición en ciencias sociales\n\n\n\n\n Abril \n\n\n\n\n\nJueves 6\n4. La medición en ciencias sociales\n\n\n\n\nJueves 13\n\nSesión 1. Introducción al lenguaje R  Sesión 2. Conocimientos básicos de programación en R\n\n\n\n\n\n\nUNIDAD 2: Medidas de tendencia central, dispersión y posición\n\n\n\nJueves 20\n5. Datos y bases de datos  6. Medidas de tendencia central\n\n\n\n\nJueves 27\n7. Medidas de dispersión  8. Medidas de posición\n\n\n\n\n Mayo \n\n\n\n\n\nJueves 4\nRECESO\n\n\n\n\nLunes 8\n\n\nEntrega Tarea Individual 1\n\n\nJueves 11\n\nSesión 3. Procesamiento, limpieza y manipulación de datos en R   Sesión 4. Medidas de tendencia central, dispersión y posición\n\n\n\nJueves 18\n\nSesión 5. Repaso Procesamiento y análisis descriptivo de datos en R\n\n\n\n\n\n\nUNIDAD 3: La forma de una distribución\n\n\n\nJueves 25\n9. Visualización y distribución de datos  10. Noción de función y distribución\n\nEntrega Tarea Individual 2\n\n\nLunes 29\n\n\nEntrega Informe 1 Taller Colectivo\n\n\n Junio \n\n\n\n\n\nJueves 1\n\nSesión 6. Visualización de datos  Sesión 7. Forma de una distribución\n\n\n\nJueves 8\nRECESO\n\n\n\n\nJueves 15\n11. Asimetría y curtosis  12. Distribución normal y puntuación Z\n\n\n\n\nJueves 22\n13. Probabilidades en la distribución normal y otras distribuciones  14. Fundamentos de la significación estadística, universo y muestra   15. Inferencia estadística univarada\n\n\n\n\n\n\n\nUNIDAD 4: Inferencia estadística univariada\n\n\n\nJueves 29\n\nSesión 8. Inferencia univariada\n\n\n\n Julio \n\n\n\n\n\nJueves 6\n\n\nEntrega Tarea Individual 3\n\n\nDomingo 9\n\n\nEntrega Informe 2 Taller Colectivo"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Programa",
    "section": "",
    "text": "Rodrigo Asún\n   Departamento de Sociología FACSO\n   rasun@uchile.cl\n\n\n\n\n\n   Jueves\n   Marzo–Julio, 2023\n   8:30 AM - 11:45 AM\n   Aulario A - sala 7 y 8"
  },
  {
    "objectID": "syllabus.html#propósito-general-del-curso",
    "href": "syllabus.html#propósito-general-del-curso",
    "title": "Programa",
    "section": "Propósito general del curso",
    "text": "Propósito general del curso\nAl finalizar el curso los estudiantes conocerán los fundamentos del análisis estadístico diferenciando entre tipos de variables, niveles de medición y formas de distribución. Se espera que los estudiantes sean capaces de diseñar y depurar bases de datos; identificar y definir diferentes tipos de muestreo; aplicar de manera pertinente, estadísticos descriptivos uni y bivariados, utilizar diferentes softwares de análisis estadístico; a partir de los cuáles puedan desarrollar análisis de problemas sociales; contrastar hipótesis de investigación; y elaborar conclusiones integrando fundamentos teóricos con herramientas de análisis estadístico de resultados. Complementariamente se espera que los estudiantes adquieran herramientas que les permitan comunicar resultados de investigación en contextos sociales, profesionales y académicos."
  },
  {
    "objectID": "syllabus.html#competencias",
    "href": "syllabus.html#competencias",
    "title": "Programa",
    "section": "Competencias",
    "text": "Competencias\n\nDelimitar, conceptualizar y analizar diversos objetos de investigación social, con especial énfasis en aquellos relacionados con los procesos de transformación del país y Latinoamérica\nManejar diversas estrategias metodológicas de las ciencias sociales\nManejar un conjunto de herramientas para el procesamiento y análisis de información\nTransmitir los conocimientos derivados de la práctica investigativa, así como aquellos adquiridos durante el proceso formativo.\n\n\nSubcompetencias\n\nContribuir a generar conocimiento sociológico en el marco de estudios y/o procesos de investigación donde se articulen creativamente las dimensiones teórica, metodológica y práctica.\nComunicar los saberes disciplinares de manera pertinente a las características de distintos contextos y audiencias, utilizando diversas estrategias y formatos."
  },
  {
    "objectID": "syllabus.html#resultados-de-aprendizaje",
    "href": "syllabus.html#resultados-de-aprendizaje",
    "title": "Programa",
    "section": "Resultados de Aprendizaje",
    "text": "Resultados de Aprendizaje\nAl finalizar el curso, los estudiantes serán capaces de:\n\nComprender la relevancia del análisis estadístico como herramienta para la investigación sociológica y la comprensión de lo social.\nConocer y manejar a nivel inicial las herramientas estadísticas e informáticas necesarias para realizar análisis y descripciones univariadas de datos sociales y sociológicos.\nResolver problemas de investigación sociológica simples a partir del uso de técnicas de cálculo, análisis y visualización estadística."
  },
  {
    "objectID": "syllabus.html#saberes-contenidos",
    "href": "syllabus.html#saberes-contenidos",
    "title": "Programa",
    "section": "Saberes / contenidos",
    "text": "Saberes / contenidos\n\nUNIDAD I. Sociología y estadística: algunas vinculaciones y conceptos fundamentales\n1.1.- ¿Por qué debe aprender estadística un estudiante o una estudiante de sociología?\n● La construcción de conocimiento sociológico y la estadística.\n● La estrategia de investigación cuantitativa: estrategia epistemológica, limitaciones y potencialidades.\n1.2.- La medición en ciencias sociales:\n● Medir en ciencias sociales: del constructo teórico al dato estadístico.\n● Tipos de variables y niveles de medición.\n● La noción de población, muestra, estadístico, parámetro y estimación.\n1.3.- Datos y bases de datos:\n● Las fuentes de información: tratamiento, producción y análisis de datos primarios y secundarios.\n● Manejo y depuración de datos y bases de datos.\n● Aspectos éticos\n\n\nUNIDAD II. La descripción de los datos: Medidas de tendencia central, dispersión y posición.\n2.1.- Medidas de tendencia central\n● Supuestos sociológicos tras las medidas de tendencia central. Ejemplos de investigaciones sociológicas relevantes.\n● La media, la media recortada, la mediana y la moda. Potencialidades y limitaciones.\n2.2.- Medidas de dispersión\n● Supuestos sociológicos tras las medidas de dispersión. Ejemplos de investigaciones sociológicas relevantes.\n● Rango, varianza y desviación típica. Coeficiente de variación. Representaciones gráficas.\n2.3.- Medidas de Posición\n● Distribuciones de frecuencias absoluta, relativa y acumulada.\n● Medidas de posición no central: los cuantiles.\n● Representaciones gráficas.\n\n\nUNIDAD III. La forma de una distribución\n● Noción de función, distribución empírica, teórica y de muestreo. Distribución discreta y distribución continua.\n● Características de la forma de una distribución: Asimetría y Curtosis.\n● Introducción a la distribución normal. Principales características de la distribución. Uso de la distribución normal. Estandarización y puntaje Z.\n● Introducción a otras distribuciones.\n\n\nUNIDAD IV. Inferencia estadística univariada: de la estimación puntual al parámetro\n● Tipos de hipótesis y prueba estadística.\n● Confianza, potencia y error.\n● Estimadores puntuales para medias y proporciones.\n● Conceptos de error típico, nivel de confianza y error de estimación.\n● La construcción de intervalos de confianza para medias y proporciones.\n● Ponderadores y sesgos en estimación de parámetros poblacionales."
  },
  {
    "objectID": "syllabus.html#metodología",
    "href": "syllabus.html#metodología",
    "title": "Programa",
    "section": "Metodología",
    "text": "Metodología\nLa asignatura se desarrollará a través de:\n\nClases lectivas o exposiciones a cargo del profesor, en las que se presentarán las principales temáticas de la asignatura, y en las que los y las estudiantes tendrán la posibilidad de resolver dudas relacionadas con los aspectos teóricos/conceptuales.\nUn Laboratorio de Análisis de Datos (LAB) a cargo del profesor y Equipo Docente. Se realizarán ejercicios prácticos de procesamiento, análisis e interpretación de resultados mediante diversos softwares de análisis estadístico (Excel, Spss y R, fundamentalmente). En ellos los y las estudiantes aprenderán a interpretar sociológicamente datos provenientes de múltiples fuentes, visualizar datos en forma gráfica, así como elaborar reportes de resultados.\nFinalmente, se realizarán sesiones de ayudantía específicas para reforzamiento de contenidos y del trabajo del Laboratorio de Análisis de Datos.\nSe reforzarán los contenidos con la entrega de material audiovisual y tutoriales"
  },
  {
    "objectID": "syllabus.html#evaluación",
    "href": "syllabus.html#evaluación",
    "title": "Programa",
    "section": "Evaluación",
    "text": "Evaluación\nDurante el transcurso de la asignatura (y en el marco del Laboratorio de Análisis de Datos) se realizará un Trabajo de Taller Colectivo (con 2 entregas a lo largo del semestre) y 3 Tareas Individuales.\n● Los grupos de Taller Colectivo (de cuatro estudiantes) tendrán asignado un/a ayudante que acompañará el proceso durante todo el semestre. Las dos entregas del taller valdrán un 30% de la nota final (60% por los talleres colectivos).\n● Se realizarán 3 Tareas Individuales. Cada tarea individual valdrá un 13,3% de la nota final (40% en total por las tareas individuales).\nPara cautelar que se logren los resultados de aprendizaje, en los Talleres Colectivos los estudiantes deberán incluir reflexiones respecto de la utilidad de la estadística para la comprensión de los temas sociológicamente relevantes que estarán analizando. Por otro parte, tanto en los Talleres Colectivos como en las Tareas Individuales los estudiantes deberán demostrar su manejo de las herramientas estadísticas e informáticas enseñadas durante el curso y producir una conclusión sustantiva sobre los datos que estén procesando, con lo que se evaluarán los resultados de aprendizaje 2 y 3."
  },
  {
    "objectID": "syllabus.html#requisitos-de-aprobación",
    "href": "syllabus.html#requisitos-de-aprobación",
    "title": "Programa",
    "section": "Requisitos de aprobación",
    "text": "Requisitos de aprobación\nASISTENCIA: Se establece una asistencia de al menos el 50% de las clases. La asistencia habilita al estudiante a presentarse al examen de primera oportunidad.\nNOTA DE APROBACIÓN MÍNIMA (Escala de 1.0 a 7.0): 4.0\nNOTA DE EXIMICIÓN MÍNIMA: 5.0\nREQUISITOS PARA PRESENTACIÓN A EXAMEN:\nPara presentarse al examen de primera oportunidad debe cumplir con: - Nota de presentación igual o superior a 3.5 - Al menos un 50% de asistencia. El estudiante se presentará al examen de segunda oportunidad en los siguientes casos: - Nota final inferior a 3.5 - Haber reprobado el curso luego de rendir el examen de primera oportunidad - No cumplimiento del mínimo de asistencia establecido en el programa (50%)."
  },
  {
    "objectID": "syllabus.html#palabras-clave",
    "href": "syllabus.html#palabras-clave",
    "title": "Programa",
    "section": "Palabras Clave",
    "text": "Palabras Clave\n\nEstadística Descriptiva, Estadística Univariada, Medidas de tendencia central, medidas de dispersión, Distribución Normal."
  },
  {
    "objectID": "syllabus.html#bibliografía-obligatoria",
    "href": "syllabus.html#bibliografía-obligatoria",
    "title": "Programa",
    "section": "Bibliografía Obligatoria",
    "text": "Bibliografía Obligatoria\n● Blalock, H. (1986). Estadística Social. México D.F.: Fondo de Cultura Económica.\n● Ferrando, M. (1999): Socioestadística: Introducción a la Estadística en Sociología. Alianza Editorial.\n● Pardo Merino, A., & San Martín Castellanos, R. (2010). Análisis de datos en ciencias sociales y de la salud II. Síntesis, Madrid.\n● Cea, D’Ancona, M. (2001). Metodología Cuantitativa. Estrategias y técnicas de investigación social. Síntesis.\n● Asún, R. (2006). Medir la Realidad Social: el sentido de la investigación cuantitativa. En: M. Canales (Ed.). Metodologías de Investigación Social (pp. 29-60). Santiago de Chile: LOM. 21.\n\nBibliografía Complementaria\n● Field, A. (2009). Discovering Statistics Using IBM SPSS. California: SAGE Publications. Disponible online en: http://www.soc.univ.kiev.ua/sites/default/files/library/elopen/andyfield-discovering-statistics-using-spss-third-edition-20091.pdf\n● Field, A., Miles, J. y Field, Z. (2012) Discovering Statistics Using R. California: SAGE Publications.\n● Boccardo, G. & Ruiz, F. (2019). RStudio para Estadística Descriptiva en Ciencias Sociales. Segunda edición. En línea en: https://bookdown.org/. Departamento de Sociología, Facultad de Ciencias Sociales, Universidad de Chile.\n● Ritchey, F. J. (2008). Estadística para las ciencias sociales. McGraw-Hill.\n● Stallman, R. (2004). Software libre para una sociedad libre. En línea en: https://www.traficantes.net/. Traficantes de Sueños.\n● Wrigth Mills, C. (1975). Empirismo abstracto. En: La imaginación sociológica. México: Fondo de Cultura Económica.\n● de Micheaux, P. L., Drouilhet, R., & Liquet, B. (2013). The R software.Fundamentals of Programming and Statistical Analysis. Springer.\n● Elousa, P. (2009). ¿Existe vida más allá del SPSS? Descubre R. En Revista Psicothema, vol.21, n° 4, pp. 652-655. Disponible online en: www.ehu.eus/gip/publicaciones/articulos/2009/2.pdf\n● González, F. (2019). Big data, algoritmos y política: las ciencias sociales en la era de las redes digitales. Revista Cinta moebio 65: pp. 267-280.\n● Grolemund & Wickham (2016). R for Data Science. Disponible en línea en: https://r4ds.had.co.nz/. O’Reilly Media.\n● Paradis, E. (2003). R para Principiantes. Francia: Institut des Sciences de l’Évolution. Disponible oline en: https://cran.r-project.org/doc/contrib/rdebuts_es.pdf\n● Urdines, F. & Cruz, A. (2019). Analiza R Datos Políticos. Instituto de Ciencia Política de la Universidad Católica de Chile. Disponible en línea: https://arcruz0.github.io/\n● Wickham, H. (2015). ggplot2: Elegant Graphics for Data Analysis. Disponible en línea en: https://ggplot2-book.org/. Springer."
  },
  {
    "objectID": "trabajos.html",
    "href": "trabajos.html",
    "title": "Trabajos",
    "section": "",
    "text": "El curso tendrá dos instancias de evaluación:\n\nTaller Colectivo: Este taller grupal (60% de la nota final) tiene por objetivo aplicar los contenidos del curso a una tématica de interés específica en formato de artículo de investigación breve. Esto implica que los estudiantes deberán plantear un fenómeno social a investigar, el problema de investigación y su relevencia, precisar el argumento o hipótesis central, describir la metodología utilizada y analizar descriptivamente variables relativas a dicho fenónomeno. Consistirá en dos informes, uno de diseño de investigación (20%) y otro de análisis y conclusiones (40%). Los talleres son elaborados en grupos de máximo 4 integrantes.\nTareas Individuales: Las tareas individuales (40% de la nota final) tienen por objetivo aplicar los contenidos del Laboratorio de Análisis de Datos y también de las clases lectivas del curso a actividades prácticas. Esto implica que los estudiantes deberán demostrar el aprendizaje de herramientas básicas de procesamiento, limpieza y manipulación de datos, además de analizar descriptivamente y visualizar variables, todo ello siendo correctamente reportado. Consistirán en 3 tareas individuales a lo largo del semestre, en donde cada una equivaldrá a un 13.3%."
  },
  {
    "objectID": "trabajos.html#taller-colectivo",
    "href": "trabajos.html#taller-colectivo",
    "title": "Trabajos",
    "section": "Taller Colectivo",
    "text": "Taller Colectivo\n\nInforme 1\nEl objetivo general de la evaluación es que los estudiantes planteen un fenómeno social a investigar, el problema de investigación y su relevancia, precisar el argumento o hipótesis central, formular una pregunta y un objetivo general de investigación, y definir la base de datos y las variables a utilizar para analizar dicho fenómeno.\nTérminos de referencia del Informe N°1 Taller Colectivo:  TDR1.pdf\n\n\nInforme 2\nEl objetivo general de la evaluación es que los estudiantes elaboren un reporte de investigación que desarrolle de forma integrada los aspectos de diseño de la investigación, análisis estadístico y presentación de resultados, así como la elaboración de conclusiones. Se espera que se integren las correcciones realizadas en la entrega previa.\nTérminos de referencia del Informe N°2 Taller Colectivo:  TDR2.pdf"
  },
  {
    "objectID": "trabajos.html#tareas-individuales",
    "href": "trabajos.html#tareas-individuales",
    "title": "Trabajos",
    "section": "Tareas Individuales",
    "text": "Tareas Individuales\n\nTarea 1\nEl objetivo de esta tarea es que los estudiantes demuestren el aprendizaje de las herramientas básicas sobre procesamiento, limpieza y manipulación de datos en los softwares Excel y SPSS (aprendidas en clases).\nPauta Tarea Individual N°1:  Tarea01.pdf\n\n\nTarea 2\nEl objetivo de esta tarea es que los estudiantes demuestren el aprendizaje de las herramientas básicas sobre procesamiento, limpieza y manipulación de datos en el software Rstudio (aprendidas en las sesiones 2 y 3 del Laboratorio), además de que analicen variables a través de medidas de tendencia central, dispersión y posición (aprendidas en sesión 4 del Laboratorio), sabiendo interpretar y reflexionar críticamente sobre los resultados obtenidos.\nPauta Tarea Individual N°2:  Tarea02.pdf\n\n\nTarea 3\nEl objetivo de esta tarea es que los estudiantes demuestren el aprendizaje de las herramientas básicas sobre visualización de datos y análisis de la forma de una distribución utilizando el software R (aprendidas en las sesiones 6 y 7 del Laboratorio), sabiendo interpretar y reflexionar críticamente sobre los resultados obtenidos.\nPauta Tarea Individual N°3:  Tarea03.pdf"
  }
]